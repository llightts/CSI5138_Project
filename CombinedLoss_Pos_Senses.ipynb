{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CombinedLoss_Pos_Senses.ipynb","provenance":[{"file_id":"1_zN-uOLU2jAYh0RzubY8R_8fOizJulA9","timestamp":1574999544597},{"file_id":"1NvrUZmv7euGSOcdduKLzscA86f55EtDa","timestamp":1574813416300}],"collapsed_sections":["AKj-XmSFUf1l","tIe4Je9DX_zf","sgPaP-U9zOGO","U0eSX24obvu9"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ZaFgi8LeluP2","colab_type":"text"},"source":["**CSI5138F - Intro to DL and RL - Project**\n","\n","This notebook is heavily influenced by the following Tutorial:\n","  https://mccormickml.com/2019/07/22/BERT-fine-tuning/ \n","\n","# Set up the notebook"]},{"cell_type":"code","metadata":{"id":"mM959ccpPygH","colab_type":"code","outputId":"ac875090-47f3-462d-b545-573e6bf757d0","executionInfo":{"status":"ok","timestamp":1574534404061,"user_tz":300,"elapsed":10398,"user":{"displayName":"Julian Templeton","photoUrl":"","userId":"10145264682205780329"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["'''\n","BASIC GUIDELINES FOR THE USAGE OF THIS NOTEBOOK\n","\n","(1) To run any section of this code, you must first run the first section ''Set up the notebook''\n","(2) For the second section ''SemCor and SensEval Parsing and Preprocessing'', it should not be necessary to run it \n","anymore since all the preprocessed data for input into the models is saved into two files already.\n","(3) However, the WiC preprocessed data was not saved into a file as for (2). Thus, to before performing training with WiC,\n","we must run the section ''WiC Preprocessing'', where the WiC preprocessing method is defined \n","(though I would recommend that we save the preprocessed data to a file just like for (2) as well)\n","(4) The fourth section \"Training and Validation\" is where we do all the training and validation and load the data for that purpose, \n","it is divided into subsections according to which model we wish to focus on. The hyperparameters and constants have been moved to that section for now, since we will probably have them for each model individually after\n","so, make sure to run all the subsections of \"Training and Validation\" if you want to make sure you have all the parameters necessary for your training\n","'''\n","\n","'''\n","THINGS TO DO:\n","\n","(1) Run the training loop of the Sense/POS Prediction Task and check that the loss is diminishing.\n","(2) Implement methods to save/load the parameters of the different models along with a name that identifies the hyperparameters (and possibly achieved loss, etc.)\n","(3)\n","'''\n","\n","'''\n","OTHER POINTS TO CONSIDER:\n","(1) It may be possible to feed words in a batchfor the finetuneingHead on senses if we assign a dummy sense/pos/lemma to the id -1. \n","We can always experiment with that if we find that feeding words one-by-one in a loop is inefficient.\n","'''\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nOTHER POINTS TO CONSIDER:\\n(1) It may be possible to feed words in a batchfor the finetuneingHead on senses if we assign a dummy sense/pos/lemma to the id -1. \\nWe can always experiment with that if we find that feeding words one-by-one in a loop is inefficient.\\n'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"q9r6NIXPkdk8","colab_type":"code","outputId":"3b82d673-2e2d-43e9-fbb6-18c0d58f4575","executionInfo":{"status":"ok","timestamp":1574998695234,"user_tz":300,"elapsed":9282,"user":{"displayName":"Simon Fortier-Garceau","photoUrl":"","userId":"08177308718689968362"}},"colab":{"base_uri":"https://localhost:8080/","height":629}},"source":["# install pytorch transformers\n","!pip install pytorch-transformers"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting pytorch-transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n","\u001b[K     |████████████████████████████████| 184kB 6.3MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 43.5MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.28.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n","\u001b[K     |████████████████████████████████| 860kB 47.9MB/s \n","\u001b[?25hCollecting regex\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n","\u001b[K     |████████████████████████████████| 645kB 45.5MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.3.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.17.4)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.10.18)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2019.9.11)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.14.0)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.18 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.13.18)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.2.1)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.4)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.18->boto3->pytorch-transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.18->boto3->pytorch-transformers) (2.6.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=7fa9db556ea8f56c2d0f48b81e405d1f408a33fb0f08eec29e877f3c1f506cbd\n","  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, sacremoses, regex, pytorch-transformers\n","Successfully installed pytorch-transformers-1.2.0 regex-2019.11.1 sacremoses-0.0.35 sentencepiece-0.1.83\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pB4NTTHlsvk1","colab_type":"text"},"source":["## Imports and mount drive"]},{"cell_type":"code","metadata":{"id":"TKkSu6q1lTco","colab_type":"code","outputId":"8e92c9e0-80d0-4306-94a1-66e7e11aa3ec","executionInfo":{"status":"ok","timestamp":1574998713738,"user_tz":300,"elapsed":17929,"user":{"displayName":"Simon Fortier-Garceau","photoUrl":"","userId":"08177308718689968362"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["import torch\n","import os\n","import string\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SubsetRandomSampler, SequentialSampler\n","from pytorch_transformers import *\n","import numpy as np\n","import json\n","from google.colab import drive\n","from sklearn.utils import shuffle\n","from sklearn.metrics import accuracy_score\n","\n","# Mount google drive containing the datasets\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LWfqbCFIstbu","colab_type":"text"},"source":["## Get RoBERTa tokenizer"]},{"cell_type":"code","metadata":{"id":"p_2mOPdyp7DZ","colab_type":"code","outputId":"ec6151c0-5441-404f-8e75-aacaed4b7d4e","executionInfo":{"status":"ok","timestamp":1574998718760,"user_tz":300,"elapsed":3236,"user":{"displayName":"Simon Fortier-Garceau","photoUrl":"","userId":"08177308718689968362"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 898823/898823 [00:00<00:00, 1809650.79B/s]\n","100%|██████████| 456318/456318 [00:00<00:00, 1349076.66B/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"ybSNiAH_WtJA","colab_type":"text"},"source":["## Utility functions"]},{"cell_type":"code","metadata":{"id":"HQhPLskGWrYJ","colab_type":"code","colab":{}},"source":["# Create a function to import json objects from jsonl files\n","def load_json_objects_from_file(filename):\n","  # Array for json objects\n","  json_objects = []\n","  # Read file line by line\n","  with open(filename, mode = \"r\") as jsonl_file:\n","      for line in jsonl_file:\n","          json_objects.append(json.loads(line))\n","  return json_objects\n","\n","# Takes a word, tokenizes it and returns the pair of positions for the FIRST occurrence of the tokens in the token_ids list\n","# NOTE: it can also apply to a group of words separated by spaces\n","#DO NOT CALL THIS METHODS DIRECTLY IF YOU WORK WITH A SENTENCE, USE THE NEXT METHOD INSTEAD: find_words_in_tokenized_sentences(wordList,token_ids) \n","def find_word_in_tokenized_sentence(word,token_ids):\n","  decomposedWord = tokenizer.encode(word)\n","  # Iterate through to find a matching sublist of the token_ids\n","  for i in range(len(token_ids)):\n","    if token_ids[i] == decomposedWord[0] and token_ids[i:i+len(decomposedWord)] == decomposedWord:\n","      return (i,i+len(decomposedWord)-1)\n","  # This is the ouput when no matching pattern is found\n","  return (-1,-1)\n","\n","# Takes a list of words (strings) and a sentence (as a RoBERTa tokenized ID list) and returns a list\n","# of pairs indicating the tokens' start and end positions in the sentence for each word\n","# NOTE: It is important that the list of words given describes a sentence, because the order is relevant to do the matching properly\n","def find_words_in_tokenized_sentences(wordList,token_ids):\n","  intList = []\n","  for word in wordList:\n","    if len(intList) == 0:\n","      intList.append(find_word_in_tokenized_sentence(word,token_ids))\n","    else:\n","      afterLastInterval = intList[-1][1]+1\n","      interv = find_word_in_tokenized_sentence(word,token_ids[afterLastInterval:])\n","      actualPositions = (interv[0] + afterLastInterval,interv[1]+afterLastInterval)\n","      intList.append(actualPositions)\n","  return intList\n","\n","# Returns the list of senses for the words of a given semcor_object\n","def sensesOf(semcor_obj):\n","  sensesList = []\n","  for j in range(len(semcor_obj['lemmatized'])):\n","    sensesList.append(semcor_obj['lemmatized'][j] + '%' + semcor_obj['lex_sense'][j])\n","  return sensesList\n","\n","\n","#Call on roberta_model and the embedding intervals of your sample to get the average of the corresponding embeddings for each word in your sample\n","def embExtract(embeddings_model,input_ids,attention_mask,emb_intervals):\n","  # Start by retrieving the embeddings from the embeddings model for input_ids and attention_mask\n","  #embeddings, _ = embeddings_model(input_ids=input_ids, attention_mask=attention_mask) # Without MaskedLM Model, don't use unless needed\n","  embeddings, _ = embeddings_model.roberta(input_ids=input_ids, attention_mask=attention_mask) # RobertaForMaskedLM model\n","  embeddings = embeddings[0]\n","  #This will hold the embeddings averaged over the appropriate interval for each word\n","  extracted_embeddings = []\n","  embedding_intervals = [[(x, y) for x, y in emb_intervals.data.tolist()[0] if x != -1]][0]\n","  \n","  for j in range(len(embedding_intervals)):\n","    temp_embeddings = torch.Tensor([0.0] * 768).to(device)\n","    start = embedding_intervals[j][0] \n","    end = embedding_intervals[j][1] \n","    for k in range(start,end+1):\n","      temp_embeddings += embeddings[k]\n","    temp_embeddings /= (end-start+1)    \n","    extracted_embeddings.append(temp_embeddings)\n","  \n","  return extracted_embeddings\n","\n","\n","def correct(pred,label): \n","  pred_actual = torch.argmax(torch.tensor(torch.nn.functional.softmax(pred)))\n","  if (pred_actual.view(-1).item() == label.view(-1).item()):\n","    return 1\n","  else:\n","    return 0\n","\n","def countCorrect(preds,labels):\n","  num_of_correct = 0\n","  total_num = 0\n","  for pred, label in zip(preds, labels):\n","    num_of_correct += correct(pred,label)\n","    total_num += 1\n","  return num_of_correct / total_num\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wrISq7OWkOAP","colab_type":"text"},"source":["## Method for the SemCor+SensEval Vocabulary"]},{"cell_type":"code","metadata":{"id":"ULR3gVeBSmwo","colab_type":"code","colab":{}},"source":["# CREATE THE SEMCOR AND SENSEVAL VOCABULARY OBJECT\n","#IT NEEDS TO BE LOADED BEFORE EVERYTHING BECAUSE BOTH THE PREPROCESSING METHODS AND THE TRAINING METHODS MAKE USE OF IT\n","\n","#This incorporates both the SemCor and SensEval vocabulary\n","class SemCor_SensEval_Vocab:\n","  def __init__(self):\n","\n","    vocab = load_json_objects_from_file(\"/content/drive/My Drive/CSI5138_Project/SemCor/semcor_senseval_vocab.jsonl\")[0]\n","\n","    # These define the three separate vocabularies for senses, lemmas and pos respectively.\n","    self.SENSES = vocab['senses']\n","    self.LEMMAS = vocab['lemmas']\n","    self.POS = vocab['POS']\n","    #for each word in the vocabulary self.WORDS[j], there is a corresponding list of all possible senses self.SENSESPACES[j] for that word, a list of possible lemmas self.LEMMASSPACES[j] and list of pos self.POSSPACES[j]\n","    self.WORDS = vocab['words']\n","    self.SENSESPACES = vocab['senseSpaces']\n","    self.LEMMASSPACES = vocab['lemmaSpaces']\n","    self.POSSPACES = vocab['posSpaces']\n","\n","  #Returns the index of a word in the vocabulary self.WORDS\n","  def getIndexOfWord(self, word):\n","    try:\n","      index_value = self.WORDS.index(word)\n","    except ValueError:\n","      index_value = -1\n","    return index_value\n","  \n","  def getIndicesOfWords(self, words):\n","    listOfWordIndices = []\n","    for j in range(len(words)):\n","      listOfWordIndices.append(self.getIndexOfWord(words[j]))\n","    return listOfWordIndices\n","  \n","  def getSenseSpaceOfWord(self,word):\n","    j = self.getIndexOfWord(word)\n","    return self.SENSESPACES[j]\n","\n","  #Returns the index of a sense in the corresponding list of senses in self.SENSESPACES for that word\n","  def giveSenseIndexOfWord(self, word,sense):\n","    wordIndex = self.getIndexOfWord(word)\n","    try:\n","      index_value = self.SENSESPACES[wordIndex].index(sense)\n","    except ValueError:\n","      index_value = -1\n","    return index_value\n","  \n","  #Returns a list of indices in the sense space for each word in the list words, in correspondance with a specific sense in senses\n","  def getSenseSpaceIndices(self, words, senses):\n","    listOfSenseIndices = []\n","    for j in range(len(words)):\n","      listOfSenseIndices.append(self.giveSenseIndexOfWord(words[j],senses[j]))\n","    \n","    return listOfSenseIndices\n","\n","    wordIndex = self.getIndexOfWord(word)\n","    try:\n","      index_value = self.SENSESPACES[wordIndex].index(sense)\n","    except ValueError:\n","      index_value = -1\n","    return index_value\n","\n","  def convertSenseID_to_Sense(self, sense_id): \n","    if sense_id == -1:\n","      return 'NO SENSE'\n","    else:\n","      return self.SENSES[sense_id]\n","\n","  def convertListSenseID_to_Sense(self, sense_id_list):\n","    senseList =[]\n","\n","    for sense_id in sense_id_list:\n","      senseList.append(self.convertSenseID_to_Sense(sense_id))\n","      \n","    return senseList\n","\n","  def convertLemmaID_to_Lemma(self, lemma_id): \n","    if lemma_id == -1:\n","      return 'NO LEMMA'\n","    else:\n","      return self.LEMMAS[lemma_id]\n","\n","  def convertListLemmaID_to_Lemma(self, lemma_id_list):\n","    lemmaList =[]\n","\n","    for lemma_id in lemma_id_list:\n","      lemmaList.append(self.convertLemmaID_to_Lemma(lemma_id))\n","      \n","    return lemmaList\n","\n","  def convertPOSID_to_POS(self, pos_id): \n","    if pos_id == -1:\n","      return 'NO POS'\n","    else:\n","      return self.POS[pos_id]\n","\n","  def convertListPOSID_to_POS(self, pos_id_list):\n","    posList =[]\n","\n","    for pos_id in pos_id_list:\n","      posList.append(self.convertPOSID_to_POS(pos_id))\n","      \n","    return posList\n","\n","  # This returns the position of a given sense in the sense vocabulary; it acts as the sense ID.\n","  def getSenseID(self, sense): \n","    return self.SENSES.index(sense)\n","\n","  # This returns a list of the positions of a given list of senses in the sense vocabulary.\n","  def getSenseIDList(self, senseList):\n","      IDList = []\n","      for exp in senseList:\n","        IDList.append(self.getSenseID(exp))\n","      return IDList\n","  \n","  # This returns the position of a given lemma in the lemma vocabulary; it acts as the lemma ID.\n","  def getLemmaID(self, lemma):\n","    return self.LEMMAS.index(lemma)\n","\n","  # This returns a list of the positions of a given list of lemmas in the lemma vocabulary.\n","  def getLemmaIDList(self, lemmaList):\n","      IDList = []\n","      for exp in lemmaList:\n","        IDList.append(self.getLemmaID(exp))\n","      return IDList    \n","\n","  # This returns the position of a given part-of-speech in the part-of-speech vocabulary; it acts as the part-of-speech ID.\n","  def getPOSID(self, pos):\n","    return self.POS.index(pos)\n","\n","  # This returns a list of the positions of a given list of lemmas in the lemma vocabulary.\n","  def getPOSIDList(self, posList):\n","      IDList = []\n","      for exp in posList:\n","        IDList.append(self.getPOSID(exp))\n","      return IDList\n","\n","  #def convertPOSIDtoPOS() :  \n","\n","# TEST THE VOCABULARY\n","#print(SEMCOR_VOCAB.LEMMAS[:10])\n","#print(SEMCOR_VOCAB.SENSES[:10])\n","#print(SEMCOR_VOCAB.POS[:10])\n","\n","#print('# of dimensions for lemmas:', len(SEMCOR_VOCAB.LEMMAS))\n","#print('# of dimensions for senses:', len(SEMCOR_VOCAB.SENSES))\n","#print('# of dimensions for POS:', len(SEMCOR_VOCAB.POS))\n","\n","#print(SEMCOR_VOCAB.getSenseID('siberia%1:15:00::'))\n","#print(SEMCOR_VOCAB.getSenseIDList(['siberia%1:15:00::', 'creativity%1:09:00::', 'foundation%1:06:00::']))\n","\n","#print(SEMCOR_VOCAB.getLemmaID('flattened'))\n","#print(SEMCOR_VOCAB.getLemmaIDList(['consolidate', 'steakhouse', 'halftime', 'margin']))\n","\n","#print(SEMCOR_VOCAB.getPOSID('WP'))\n","#print(SEMCOR_VOCAB.getPOSIDList(['WP$', 'WP','RB']))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HmltxK8z3yUt","colab_type":"code","colab":{}},"source":["#SEMCOR_VOCAB = SemCor_SensEval_Vocab()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"acf59084-8883-421e-f37b-5ff2b3ee65dd","executionInfo":{"status":"ok","timestamp":1574810828171,"user_tz":300,"elapsed":381,"user":{"displayName":"Simon Fortier-Garceau","photoUrl":"","userId":"08177308718689968362"}},"id":"TnarcOwRIltA","colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["print(SEMCOR_VOCAB.WORDS[100])\n","print(SEMCOR_VOCAB.SENSESPACES[100])\n","print(SEMCOR_VOCAB.POSSPACES[100])\n","\n","wordIndex = SEMCOR_VOCAB.getIndexOfWord('mother')\n","print(wordIndex)\n","\n","senseIndex = SEMCOR_VOCAB.giveSenseIndexOfWord(SEMCOR_VOCAB.WORDS[wordIndex],'mother%1:18:00::')\n","print(senseIndex)\n","\n","words = [SEMCOR_VOCAB.WORDS[100],SEMCOR_VOCAB.WORDS[200],SEMCOR_VOCAB.WORDS[350],SEMCOR_VOCAB.WORDS[112]]\n","\n","#print(SEMCOR_VOCAB.getSenseSpaceOfWord(words[0]))\n","#print(SEMCOR_VOCAB.getSenseSpaceOfWord(words[1]))\n","#print(SEMCOR_VOCAB.getSenseSpaceOfWord(words[2]))\n","#print(SEMCOR_VOCAB.getSenseSpaceOfWord(words[3]))\n","\n","senses = [SEMCOR_VOCAB.getSenseSpaceOfWord(words[0])[0], SEMCOR_VOCAB.getSenseSpaceOfWord(words[1])[1], SEMCOR_VOCAB.getSenseSpaceOfWord(words[2])[1],SEMCOR_VOCAB.getSenseSpaceOfWord(words[3])[0] ]\n","\n","print(words)\n","print(senses)\n","\n","\n","SEMCOR_VOCAB.getSenseSpaceIndices(words,senses)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["mother\n","['mother%1:18:00::']\n","['NN']\n","100\n","0\n","['mother', 'ten', 'recent', 'trisodium orthophosphate']\n","['mother%1:18:00::', 'ten%None', 'recent%5:00:00:past:00', 'trisodium_orthophosphate%1:27:00::']\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0, 1, 1, 0]"]},"metadata":{"tags":[]},"execution_count":102}]},{"cell_type":"markdown","metadata":{"id":"AKj-XmSFUf1l","colab_type":"text"},"source":["# SemCor and SensEval Parsing and Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"PquFQhfHSYs2","colab_type":"text"},"source":["## SemCor and SensEval Vocabulary Preprocessing"]},{"cell_type":"code","metadata":{"id":"BJ6aIy2mSu4E","colab_type":"code","outputId":"8da66e11-6de0-4804-a716-c9f88dbc6068","executionInfo":{"status":"ok","timestamp":1574810442306,"user_tz":300,"elapsed":303503,"user":{"displayName":"Simon Fortier-Garceau","photoUrl":"","userId":"08177308718689968362"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["# CREATES THE SEMCOR + SENSEVAL VOCABULARY FILE FOR LEMMAS, SENSES AND POS AND STORES IT IN\n","#/content/drive/My Drive/CSI5138_Project/SemCor/semcor_senseval_vocab.jsonl\n","def createVocabFile():\n","  semcor_json_objs = load_json_objects_from_file(\"/content/drive/My Drive/CSI5138_Project/SemCor/semcor_parsed2nd.jsonl\")\n","  senseval_json_objs = load_json_objects_from_file(\"/content/drive/My Drive/CSI5138_Project/SensEval/senseval.jsonl\")\n","\n","  vocabulary = {\n","      \"words\" : [],\n","      \"lemmas\" : [],\n","      \"senses\" : [],\n","      \"POS\" : [],\n","      \"senseSpaces\" : [],\n","      \"lemmaSpaces\" : [],\n","      \"posSpaces\" : []\n","      }\n","\n","  words = []\n","  lemmas = []\n","  senses = []\n","  POS = []\n","\n","  for obj in semcor_json_objs:\n","    words.extend(obj['wordList'])\n","    lemmas.extend(obj['lemmatized'])\n","    senses.extend(sensesOf(obj))\n","    POS.extend(obj['pos'])\n","\n","\n","  \n","\n","  for obj in senseval_json_objs:\n","    words.extend(obj['wordList'])\n","    lemmas.extend(obj['lemmatized'])\n","    senses.extend(sensesOf(obj))\n","    POS.extend(obj['pos'])\n","\n","  print(words[5620])\n","  print(senses[5620])\n","\n","\n","  vocabulary['words'] = list(set(words))\n","  vocabulary['lemmas'] = list(set(lemmas))\n","  vocabulary['senses'] = list(set(senses))\n","  vocabulary['POS'] = list(set(POS))\n","\n","  \n","\n","\n","  for word in vocabulary['words']:\n","    listOfSensesOfWord =[]\n","    listOfLemmasOfWord =[]    \n","    listOfPOSOfWord =[]\n","    for j in range(len(words)):\n","      if words[j] == word:\n","        listOfSensesOfWord.append(senses[j])\n","        listOfLemmasOfWord.append(lemmas[j])\n","        listOfPOSOfWord.append(POS[j])\n","    listOfSensesOfWord = list(set(listOfSensesOfWord))\n","    listOfLemmasOfWord = list(set(listOfLemmasOfWord))\n","    listOfPOSOfWord = list(set(listOfPOSOfWord))\n","    vocabulary['senseSpaces'].append(listOfSensesOfWord)\n","    vocabulary['lemmaSpaces'].append(listOfLemmasOfWord)\n","    vocabulary['posSpaces'].append(listOfPOSOfWord)\n","\n","\n","  \n","  print(len(vocabulary['words']))  \n","  print(len(vocabulary['senseSpaces']))\n","  print(len(vocabulary['lemmaSpaces']))\n","  print(len(vocabulary['posSpaces']))\n","\n","\n","  #incorporating SensEval to the SemCor vocabulary shifted the number of lemmas from 17176 to 17764\n","  #incorporating SensEval to the SemCor vocabulary shifted the number of senses from 25573 to 26898\n","  #incorporating SensEval to the SemCor vocabulary shifted the number of POS from 39 to 45 (this could affect performance since there are 6 unknown POS, though they probably arise very rarely)\n","  #In sum, there are no major shifts in the size of the vocabulary\n","\n","  with open('/content/drive/My Drive/CSI5138_Project/SemCor/semcor_senseval_vocab.jsonl', mode = \"w\") as vocab_file:\n","      vocab_file.write(json.dumps(vocabulary))\n","\n","#LAUNCH THE METHOD\n","createVocabFile()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["news\n","news%1:10:00::\n","25457\n","25457\n","25457\n","25457\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UsS0lPCfnVp1","colab_type":"text"},"source":["## Parse the SemCor data\n","(to the file: '/content/drive/My Drive/CSI5138_Project/SemCor/semcor_parsed2nd.jsonl')"]},{"cell_type":"code","metadata":{"id":"aXumjT8O5GwU","colab_type":"code","colab":{}},"source":["'''\n","    CSI5138F - Word in Context Project\n","    Project Group 4\n","    Members:\n","        - William Larocque\n","        - Simon Fortier-Garceau\n","        - Julian Templeton\n","    ---------------------------\n","    This file is for parsing the semcor corpus which we will use as the training set.\n","    Based on http://www.nltk.org/howto/corpus.html#other-corpora and https://docs.python.org/3.7/library/xml.etree.elementtree.html\n","'''\n","from xml.etree import ElementTree as ET\n","from os import listdir\n","from os.path import join\n","import json\n","\n","def parseSemCor():\n","  file_location = \"/content/drive/My Drive/CSI5138_Project/SemCor/tagfiles\"\n","  semcor_files = [file for file in listdir(file_location) if '.xml' in file]\n","  # Buffer array to get all sentences of semcor\n","  parsed_semcor = []\n","  # Parse every file\n","  for xml_file in semcor_files:\n","      # Get all the sentences in the file\n","      sentences = ET.parse(join(file_location, xml_file)).findall('context/p/s')\n","      for sentence in sentences:\n","        \n","        parsed_sentence = {\n","            \"sentence\" : \"\",\n","            \"wordList\" : [],\n","            \"lemmatized\" : [],\n","            \"pos\" : [],\n","            \"wordnet\" : [],\n","            \"lex_sense\" : [],\n","            \"source_file\" : xml_file\n","            }\n","        # Deal with every word individually\n","        for token in sentence: # We only care about the words not the punctuation of the sentence\n","              # Get the token attribute            \n","              token_attrib = token.attrib\n","\n","              #replace the underscore in word groups and replace with whitespace to facilitate proper tokenization\n","              token.text = token.text.replace('_', ' ')\n","\n","              # Append word POS\n","              if 'pos' in token_attrib:\n","                parsed_sentence[\"pos\"].append(token_attrib['pos'])\n","              else:\n","                parsed_sentence[\"pos\"].append('PUNC')\n","\n","              # Look for a lemmatize word, else just append word as-is\n","              if 'lemma' in token_attrib:\n","                parsed_sentence[\"lemmatized\"].append(token_attrib['lemma'])\n","              else:\n","                parsed_sentence[\"lemmatized\"].append(token.text)\n","\n","              # Look for word sense, else append None.\n","              if 'wnsn' in token_attrib:\n","                  parsed_sentence[\"wordnet\"].append(token_attrib[\"wnsn\"])\n","              else:\n","                  parsed_sentence[\"wordnet\"].append(None)\n","\n","              # Look for lemma sense, else append None\n","              if 'lexsn' in token_attrib:\n","                  parsed_sentence[\"lex_sense\"].append(token_attrib[\"lexsn\"])\n","              else:\n","                  parsed_sentence[\"lex_sense\"].append('None')\n","\n","              # Add word to sentence\n","              parsed_sentence[\"wordList\"].append(token.text)\n","\n","        parsed_sentence[\"sentence\"] = \" \".join(parsed_sentence[\"wordList\"])\n","\n","        # Append to parsed_semcor\n","        parsed_semcor.append(parsed_sentence)\n","\n","  with open('/content/drive/My Drive/CSI5138_Project/SemCor/semcor_parsed2nd.jsonl', mode = \"w\") as parsed_file:\n","      for entry in parsed_semcor:\n","          parsed_file.write(json.dumps(entry) + \"\\n\")\n","\n","#LAUNCH THE METHOD\n","parseSemCor()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ter03XyP0QSK","colab_type":"code","outputId":"42ccdc83-ef0d-480c-eb72-56f15ea998cb","executionInfo":{"status":"ok","timestamp":1574488824815,"user_tz":300,"elapsed":445,"user":{"displayName":"Simon Fortier-Garceau","photoUrl":"","userId":"08177308718689968362"}},"colab":{"base_uri":"https://localhost:8080/","height":328}},"source":["#TEST THE PARSED SEMCOR FILE\n","#Punctuation has been added\n","semcor_json_objs = load_json_objects_from_file(\"/content/drive/My Drive/CSI5138_Project/SemCor/semcor_parsed2nd.jsonl\")\n","#print(f\"Number of training examples = {len(semcor_json_objs)}\")\n","#print(semcor_json_objs[0])\n","\n","#sentence for RoBERTa tokenization example\n","s =  semcor_json_objs[0]['sentence']\n","print(s)\n","\n","totalwords = 0\n","for j in range(len(semcor_json_objs)):\n","  for t in semcor_json_objs[j]['lex_sense']:\n","    totalwords += 1\n","\n","token_ids = tokenizer.encode(s)\n","tokens = tokenizer.convert_ids_to_tokens(token_ids)\n","sentence = tokenizer.convert_tokens_to_string(tokens)\n","\n","print(\"As we can see, the RoBERTa tokenizer can (more or less) recover a sentence in its original format with convert_tokens_to_string:\\n\")\n","print('Original sentence:', s)\n","print('Derived from RoBERTa tokens:', sentence)\n","print('\\n')\n","#there is an added whitespace at the beginning of the sentence\n","\n","print(\"We can also compare the list of words of a SemCor sentence with the token assignment of RoBERTa on the sentence obtained by joining with whitespace.\\n\")\n","print('List of words of SemCor sentence:', semcor_json_objs[0]['wordList'])\n","print('Derived RoBERTa tokenization:', tokens)\n","print('\\n')\n","print(\"We remark that the group of words -a hundred- gets two separate tokens, and -myrrh- gets broken down into three segments.\\n\")\n","\n","#print(\"But we can find the specific interval of tokens that characterizes the words of the SemCor list.\\n\")\n","#for i in range(len(semcor_json_objs[0]['wordList'])):\n","#  print(\"Token interval for -\", semcor_json_objs[0]['wordList'][i], \"- is \"  , intervalOfMatchTokens(semcor_json_objs[0]['wordList'][i],token_ids))\n","\n","print(totalwords)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["He brought with him a mixture of myrrh and aloes , of about a hundred pounds ' weight .\n","As we can see, the RoBERTa tokenizer can (more or less) recover a sentence in its original format with convert_tokens_to_string:\n","\n","Original sentence: He brought with him a mixture of myrrh and aloes , of about a hundred pounds ' weight .\n","Derived from RoBERTa tokens:  He brought with him a mixture of myrrh and aloes , of about a hundred pounds ' weight .\n","\n","\n","We can also compare the list of words of a SemCor sentence with the token assignment of RoBERTa on the sentence obtained by joining with whitespace.\n","\n","List of words of SemCor sentence: ['He', 'brought', 'with', 'him', 'a', 'mixture', 'of', 'myrrh', 'and', 'aloes', ',', 'of', 'about', 'a hundred', 'pounds', \"'\", 'weight', '.']\n","Derived RoBERTa tokenization: ['ĠHe', 'Ġbrought', 'Ġwith', 'Ġhim', 'Ġa', 'Ġmixture', 'Ġof', 'Ġmy', 'r', 'rh', 'Ġand', 'Ġal', 'oes', 'Ġ,', 'Ġof', 'Ġabout', 'Ġa', 'Ġhundred', 'Ġpounds', \"Ġ'\", 'Ġweight', 'Ġ.']\n","\n","\n","We remark that the group of words -a hundred- gets two separate tokens, and -myrrh- gets broken down into three segments.\n","\n","229358\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ewdLL07spAtM"},"source":["## Parse the SensEval data\n","(to the file: '/content/drive/My Drive/CSI5138_Project/SensEval/senseval.jsonl')"]},{"cell_type":"code","metadata":{"id":"6VsRuXdE4meY","colab_type":"code","colab":{}},"source":["'''\n","    CSI5138F - Word in Context Project\n","    Project Group 4\n","    Members:\n","        - William Larocque\n","        - Simon Fortier-Garceau\n","        - Julian Templeton\n","    ---------------------------\n","    This file is for parsing the semcor corpus which we will use as the training set.\n","    Based on http://www.nltk.org/howto/corpus.html#other-corpora and https://docs.python.org/3.7/library/xml.etree.elementtree.html\n","'''\n","from xml.etree import ElementTree as ET\n","from os import listdir\n","from os.path import join\n","import json\n","\n","def parseSensEval():\n","  file_location = \"/content/drive/My Drive/CSI5138_Project/SensEval/WNet3Set\"\n","  semcor_files = [file for file in listdir(file_location) if '.xml' in file]\n","  # Buffer array to get all sentences of semcor\n","  parsed_semcor = []\n","  # Parse every file\n","  for xml_file in semcor_files:\n","      # Get all the sentences in the file\n","      sentences = ET.parse(join(file_location, xml_file)).findall('context/p/s')\n","      for sentence in sentences:\n","        \n","        parsed_sentence = {\n","            \"sentence\" : \"\",\n","            \"wordList\" : [],\n","            \"lemmatized\" : [],\n","            \"pos\" : [],\n","            \"wordnet\" : [],\n","            \"lex_sense\" : [],\n","            \"source_file\" : xml_file\n","            }\n","        # Deal with every word individually\n","        for token in sentence: # We only care about the words not the punctuation of the sentence\n","              # Get the token attribute            \n","              token_attrib = token.attrib\n","\n","              #replace the underscore in word groups and replace with whitespace to facilitate proper tokenization\n","              token.text = token.text.replace('_', ' ')\n","\n","              # Append word POS\n","              if 'pos' in token_attrib:\n","                parsed_sentence[\"pos\"].append(token_attrib['pos'])\n","              else:\n","                parsed_sentence[\"pos\"].append('PUNC')\n","\n","              # Look for a lemmatize word, else just append word as-is\n","              if 'lemma' in token_attrib:\n","                parsed_sentence[\"lemmatized\"].append(token_attrib['lemma'])\n","              else:\n","                parsed_sentence[\"lemmatized\"].append(token.text)\n","\n","              # Look for word sense, else append None.\n","              if 'wnsn' in token_attrib:\n","                  parsed_sentence[\"wordnet\"].append(token_attrib[\"wnsn\"])\n","              else:\n","                  parsed_sentence[\"wordnet\"].append(None)\n","\n","              # Look for lemma sense, else append None\n","              if 'lexsn' in token_attrib:\n","                  parsed_sentence[\"lex_sense\"].append(token_attrib[\"lexsn\"])\n","              else:\n","                  parsed_sentence[\"lex_sense\"].append('None')\n","\n","              # Add word to sentence\n","              parsed_sentence[\"wordList\"].append(token.text)\n","\n","        parsed_sentence[\"sentence\"] = \" \".join(parsed_sentence[\"wordList\"])\n","\n","        # Append to parsed_semcor\n","        parsed_semcor.append(parsed_sentence)\n","\n","  with open('/content/drive/My Drive/CSI5138_Project/SensEval/senseval.jsonl', mode = \"w\") as parsed_file:\n","      for entry in parsed_semcor:\n","          parsed_file.write(json.dumps(entry) + \"\\n\")\n","\n","#LAUNCH THE METHOD\n","parseSensEval()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6E7CeSv857RU","colab_type":"code","outputId":"ce25255c-ae73-47a3-9cb8-45710363d6f0","executionInfo":{"status":"ok","timestamp":1574488839280,"user_tz":300,"elapsed":277,"user":{"displayName":"Simon Fortier-Garceau","photoUrl":"","userId":"08177308718689968362"}},"colab":{"base_uri":"https://localhost:8080/","height":90}},"source":["#TESTING THE PARSED SENSEVAL\n","senseval_json_objs = load_json_objects_from_file(\"/content/drive/My Drive/CSI5138_Project/SensEval/senseval.jsonl\")\n","\n","countNOANS = 0\n","countU = 0\n","countNOWN = 0\n","totalwords = 0\n","for j in range(len(senseval_json_objs)):\n","  for t in senseval_json_objs[j]['lex_sense']:\n","    totalwords += 1\n","    if t == 'NOANSWER':\n","      countNOANS += 1\n","    if t == 'U':\n","      countU += 1\n","    if t == 'NOWN':\n","      countNOWN += 1\n","\n","\n","print(totalwords)\n","print(countNOANS) #These have no adequate sense identification\n","print(countU) #These words have an unknown sense\n","print(countNOWN) #The answer provided for some collocations consists of two senses for two different words.\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["11100\n","40\n","112\n","28\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sKKdk40zXFHy","colab_type":"text"},"source":["## Preprocess the SemCor and SensEval\n","\n","(This gives the input for the models and are saved into their respective files:\n","'CSI5138_Project/SensEval/preprocessed_semcor.jsonl' and \n","'CSI5138_Project/SensEval/preprocessed_senseval.jsonl'\n"]},{"cell_type":"markdown","metadata":{"id":"Sh2TP38OqYf-","colab_type":"text"},"source":["### Method for preprocessing Semcor (or SensEval)"]},{"cell_type":"code","metadata":{"id":"K8f2qtuyXOzv","colab_type":"code","colab":{}},"source":["#A method to preprocess the SemCor or SenEval data\n","def sense_preprocessing(semcor_objects, testing = True, shuffle_data = False):\n","\n","  SEMCOR_VOCAB = SemCor_SensEval_Vocab()\n","\n","\n","\n","  semcor_sentences = []\n","  semcor_senses = []\n","  semcor_lemmas = []  \n","  semcor_pos = []\n","  semcor_wordLists = []\n","  semcor_senseSpaceIDs = []\n","\n","\n","\n","  semcor_encoded = []\n","  semcor_token_intervals = []\n","\n","  for example in semcor_objects:\n","    sentence = f\"<s>{example['sentence']}</s>\"\n","\n","    semcor_sentences.append(sentence)\n","    semcor_senses.append(sensesOf(example))\n","    #print(sensesOf(example))\n","    semcor_lemmas.append(example['lemmatized'])\n","    semcor_pos.append(example['pos'])\n","    semcor_wordLists.append(example['wordList'])\n","    semcor_senseSpaceIDs.append(SEMCOR_VOCAB.getSenseSpaceIndices(example['wordList'],sensesOf(example)))\n","\n","\n","    # Then encode the sentences\n","    semcor_encoded.append(tokenizer.encode(sentence, add_special_tokens=False))  #maybe this is wrong and requires sentence directly with special tokens (check later)\n","\n","    \n","  # Pad the sequences and find the encoded word location in the combined input\n","  #max_len = np.array([len(ex) for ex in semcor_encoded]).max()\n","  #max number of tokens in a sentence\n","  max_len = 151\n","\n","  #max number of words in a sentence\n","  #max_len_sentence = np.array([len(ex) for ex in semcor_senses]).max()\n","  max_len_sentence = 134\n","\n","  semcor_padded = {\"input_ids\" : [], \"attention_mask\" : [], \"sense_ids\": [], \"pos_ids\" : [], 'lemma_ids' : [], \"emb_intervals\" : [], \"wordList\" : [], \"sense_spaceids\":[]}\n","  \n","\n","  for j in range(len(semcor_senses)):    \n","    semcor_padded['sense_spaceids'].append(semcor_senseSpaceIDs[j])\n","    semcor_padded['sense_spaceids'][j].extend([-1]*(max_len_sentence-len(semcor_padded['sense_spaceids'][j])))\n","    semcor_padded['sense_ids'].append(SEMCOR_VOCAB.getSenseIDList(semcor_senses[j]))\n","    semcor_padded['sense_ids'][j].extend([-1]*(max_len_sentence-len(semcor_padded['sense_ids'][j])))\n","    semcor_padded['pos_ids'].append(SEMCOR_VOCAB.getPOSIDList(semcor_pos[j]))\n","    semcor_padded['pos_ids'][j].extend([-1]*(max_len_sentence-len(semcor_padded['pos_ids'][j])))\n","    semcor_padded['lemma_ids'].append(SEMCOR_VOCAB.getLemmaIDList(semcor_lemmas[j]))\n","    semcor_padded['lemma_ids'][j].extend([-1]*(max_len_sentence-len(semcor_padded['lemma_ids'][j])))\n","    semcor_padded['wordList'].append(semcor_wordLists[j])\n","    #print('Changing to ids and padding:', j, ' with ', semcor_padded['sense_ids'][j])\n","\n","\n","  for i in range(0, len(semcor_encoded)):\n","    enc_sentence = semcor_encoded[i]\n","    #word_locs = wic_word_locs[i]\n","\n","\n","    # Pad the sequences\n","    ex_len = len(enc_sentence)\n","    padded_sentence = enc_sentence.copy()\n","    padded_sentence.extend([0]*(max_len - ex_len))\n","    semcor_padded[\"input_ids\"].append(padded_sentence)\n","\n","    semcor_padded[\"emb_intervals\"].append(find_words_in_tokenized_sentences(semcor_wordLists[i],padded_sentence))\n","\n","    #lastIntervalOfCurrent = semcor_padded[\"emb_intervals\"][i][-1]\n","    lastIntervalOfCurrent = (-1, -1)\n","\n","    semcor_padded[\"emb_intervals\"][i].extend([lastIntervalOfCurrent]*(max_len_sentence-len(semcor_padded[\"emb_intervals\"][i])))\n","\n","    #print('Processing intervals:', i, ' with ', semcor_padded[\"emb_intervals\"][i])\n","\n","    padded_mask = [1] * ex_len\n","    padded_mask.extend([0]*(max_len - ex_len))\n","    semcor_padded[\"attention_mask\"].append(padded_mask)\n","    \n","  if testing:\n","    if shuffle_data:\n","      # Shuffle the data\n","      raw_set = {\"input_ids\" : [], \"attention_mask\" : [], \"senses\": [], \"pos\" : [], 'lemmas' : [], \"emb_intervals\" : [], \"wordList\" : [], \"sense_spaceids\": []}\n","      raw_set[\"input_ids\"], raw_set[\"attention_mask\"], raw_set[\"sense_ids\"], raw_set[\"pos_ids\"], raw_set[\"lemma_ids\"], raw_set[\"emb_intervals\"], raw_set[\"wordList\"], raw_set[\"sense_spaceids\"] = shuffle(semcor_padded[\"input_ids\"],\n","                                                                                                                                                                                                          semcor_padded[\"attention_mask\"],\n","                                                                                                                                                                                                          semcor_padded[\"sense_ids\"],\n","                                                                                                                                                                                                          semcor_padded[\"pos_ids\"],\n","                                                                                                                                                                                                          semcor_padded[\"lemma_ids\"],\n","                                                                                                                                                                                                          semcor_padded[\"emb_intervals\"],\n","                                                                                                                                                                                                          semcor_padded[\"wordList\"],\n","                                                                                                                                                                                                          semcor_padded[\"sense_spaceids\"])\n","    else:\n","      raw_set = {\"input_ids\": semcor_padded[\"input_ids\"], \"attention_mask\": semcor_padded[\"attention_mask\"], \"sense_ids\": semcor_padded[\"sense_ids\"],\n","                 \"pos_ids\": semcor_padded[\"pos_ids\"], \"lemma_ids\" : semcor_padded[\"lemma_ids\"], \"emb_intervals\" : semcor_padded[\"emb_intervals\"], \"wordList\" : semcor_padded[\"wordList\"], \"sense_spaceids\": semcor_padded[\"sense_spaceids\"] }\n","  else: # No labels present (Testing set)\n","    # Do not shuffle the testing set\n","    raw_set = {\"input_ids\": semcor_padded[\"input_ids\"], \"attention_mask\": semcor_padded[\"attention_mask\"], \"sense_ids\": semcor_padded[\"sense_ids\"],\n","                 \"pos_ids\": semcor_padded[\"pos_ids\"], \"lemma_ids\" : semcor_padded[\"lemma_ids\"], \"emb_intervals\" : semcor_padded[\"emb_intervals\"], \"wordList\" : semcor_padded[\"wordList\"], \"sense_spaceids\": semcor_padded[\"sense_spaceids\"] }\n","  # Return the raw data (Need to put them in a PyTorch tensor and dataset)\n","  return raw_set\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"86ozE7cJqqiC","colab_type":"text"},"source":["### Preprocess SemCor and save to file"]},{"cell_type":"code","metadata":{"id":"mk0GPT9nX9O8","colab_type":"code","colab":{}},"source":["#This function saves the preprocessed SemCor Training data to 'preprocessed_semcor.jsonl' for quick loading\n","def savePreprocSemcor():\n","  semcor_json_objs = load_json_objects_from_file(\"/content/drive/My Drive/CSI5138_Project/SemCor/semcor_parsed2nd.jsonl\")\n","  raw_train_set = sense_preprocessing(semcor_json_objs, testing = False)\n","  data = []\n","  data.append(raw_train_set['input_ids'])\n","  data.append(raw_train_set['attention_mask'])\n","  data.append(raw_train_set['sense_ids'])\n","  data.append(raw_train_set['pos_ids'])\n","  data.append(raw_train_set['lemma_ids'])\n","  data.append(raw_train_set['emb_intervals'])\n","  data.append(raw_train_set['wordList'])\n","  data.append(raw_train_set['sense_spaceids'])\n","  \n","  with open('/content/drive/My Drive/CSI5138_Project/SensEval/preprocessed_semcor.jsonl', mode = \"w\") as preproc_file:\n","    for entry in data:\n","      preproc_file.write(json.dumps(entry) + \"\\n\")\n","\n","\n","#Execute the procedure in question\n","savePreprocSemcor()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eH5Z_hHFq3Rp"},"source":["### Preprocess SensEval and save to file"]},{"cell_type":"code","metadata":{"id":"0g77HA_3Qudh","colab_type":"code","colab":{}},"source":["#This function saves the preprocessed SensEval Evaluation data to 'preprocessed_senseval.jsonl' for quick loading\n","def savePreprocSenseval():\n","  senseval_json_objs = load_json_objects_from_file(\"/content/drive/My Drive/CSI5138_Project/SensEval/senseval.jsonl\")\n","  raw_eval_set = sense_preprocessing(senseval_json_objs, testing = True)\n","  data = []\n","  data.append(raw_eval_set['input_ids'])\n","  data.append(raw_eval_set['attention_mask'])\n","  data.append(raw_eval_set['sense_ids'])\n","  data.append(raw_eval_set['pos_ids'])\n","  data.append(raw_eval_set['lemma_ids'])\n","  data.append(raw_eval_set['emb_intervals'])\n","  data.append(raw_eval_set['wordList'])\n","  data.append(raw_eval_set['sense_spaceids'])\n","  \n","  with open('/content/drive/My Drive/CSI5138_Project/SensEval/preprocessed_senseval.jsonl', mode = \"w\") as preproc_file:\n","    for entry in data:\n","      preproc_file.write(json.dumps(entry) + \"\\n\")\n","\n","\n","#Execute the procedure in question\n","savePreprocSenseval()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MsMDOM8Ud7KQ","colab_type":"code","colab":{}},"source":["\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tIe4Je9DX_zf","colab_type":"text"},"source":["# WiC Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"sgPaP-U9zOGO","colab_type":"text"},"source":["## Method for Preprocessing the WordInContext datasets"]},{"cell_type":"code","metadata":{"id":"UFrrDdukUvwn","colab_type":"code","colab":{}},"source":["# Create a function to preprocess the WiC data\n","def wic_preprocessing(json_objects, testing = True, shuffle_data = False, verbose = False):\n","  wic_sentences = []\n","  wic_encoded = []\n","  wic_labels = []\n","  wic_word_locs = []\n","  for example in json_objects:\n","    sentence = f\"<s>{example['sentence1']}</s><s>{example['sentence2']}</s>\"\n","    wic_sentences.append(sentence)\n","    # Then encode the sentences\n","    wic_encoded.append(tokenizer.encode(sentence, add_special_tokens=False))\n","    # Find the word in each sentences\n","    word = example['word']\n","    word_locs = (-1, -1)\n","    # Split the 2 sentences on space. (Also, lemmatize and uncapitilize each word)\n","    sent1_split = example['sentence1'].split(' ')\n","    sent2_split = example['sentence2'].split(' ')\n","    # Get the index of word in both sentences\n","    sent1_word_char_loc = (example['start1'], example['end1'])\n","    sent2_word_char_loc = (example['start2'], example['end2'])\n","    # Create a variable to keep track of the number of characters parsed in each sentence as we loop\n","    sent_chars = 0\n","    # Loop over the words in the first sentence\n","    i, j = 0, 0\n","    word1_not_found, word2_not_found = True, True\n","    while word1_not_found and i < len(sent1_split):\n","      if sent_chars >= sent1_word_char_loc[0] and sent_chars <= sent1_word_char_loc[1]:\n","        word_locs = (i, -1) # Found the word in the sentence\n","        word1_not_found = False\n","      elif sent_chars > sent1_word_char_loc[1]:\n","        # If we somehow got past the word. Assume it was the previous word\n","        word_locs = (i - 1, -1) # Found the word in the sentence\n","        word1_not_found = False\n","      else:\n","        # Look at the next word\n","        sent_chars += len(sent1_split[i]) + 1 # Plus one for the space\n","        i += 1\n","    # Loop over the words in the second\n","    sent_chars = 0 # Reset\n","    while word2_not_found and j < len(sent2_split):\n","      if sent_chars >= sent2_word_char_loc[0] and sent_chars <= sent2_word_char_loc[1]:\n","        word_locs = (i, j) # Found the word in the sentence\n","        word2_not_found = False\n","      elif sent_chars > sent2_word_char_loc[1]:\n","        # If we somehow got past the word. Assume it was the previous word\n","        word_locs = (i, j - 1) # Found the word in the sentence\n","        word2_not_found = False\n","      else:\n","        # Look at the next word\n","        sent_chars += len(sent2_split[j]) + 1 # Plus one for the space\n","        j += 1\n","    # For testing\n","    if verbose:\n","      print(word)\n","      print(sent1_split)\n","      print(sent2_split)\n","      print(word_locs)\n","    # Now to find the word in the tokenized sentences\n","    word1 = sent1_split[word_locs[0]].translate(str.maketrans('', '', string.punctuation)) #Remove punctuation (See https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string)\n","    word2 = sent2_split[word_locs[1]].translate(str.maketrans('', '', string.punctuation)) #Remove punctuation\n","    token_word_locs = find_words_in_tokenized_sentences([word1, word2], wic_encoded[-1])\n","    wic_word_locs.append(token_word_locs)\n","    # Get the label if we expect it to be there\n","    if testing:\n","      if example['label']:\n","        wic_labels.append(1)\n","      else:\n","        wic_labels.append(0)\n","  # Pad the sequences and find the encoded word location in the combined input\n","  max_len = np.array([len(ex) for ex in wic_encoded]).max()\n","  wic_padded = {\"input_ids\" : [], \"attention_mask\" : [], \"token_type_ids\" : [], \"word1_locs\": [], \"word2_locs\" : []}\n","  for i in range(0, len(wic_encoded)):\n","    enc_sentence = wic_encoded[i]\n","    word_locs = wic_word_locs[i]\n","    # Pad the sequences\n","    ex_len = len(enc_sentence)\n","    padded_sentence = enc_sentence.copy()\n","    padded_sentence.extend([0]*(max_len - ex_len))\n","    wic_padded[\"input_ids\"].append(padded_sentence)\n","    padded_mask = [1] * ex_len\n","    padded_mask.extend([0]*(max_len - ex_len))\n","    wic_padded[\"attention_mask\"].append(padded_mask)\n","    # Create the vector to get back the words after RoBERTa\n","    token_word_locs = wic_word_locs[i]\n","    first_word_loc = []\n","    second_word_loc = []\n","    len_first_word = token_word_locs[0][1] - token_word_locs[0][0] + 1\n","    len_second_word = token_word_locs[1][1] - token_word_locs[1][0] + 1\n","    for j in range(0, max_len):\n","      if j >= token_word_locs[0][0] and j <= token_word_locs[0][1]:\n","        # Part of the first word\n","        first_word_loc.append(1.0 / len_first_word)\n","      else:\n","        first_word_loc.append(0.0)\n","      if j >= token_word_locs[1][0] and j <= token_word_locs[1][1]:\n","        # Part of the second word\n","        second_word_loc.append(1.0 / len_second_word)\n","      else:\n","        second_word_loc.append(0.0)\n","    wic_padded[\"word1_locs\"].append(first_word_loc)\n","    wic_padded[\"word2_locs\"].append(second_word_loc)\n","    # token_type_ids is a mask that tells where the first and second sentences are\n","    token_type_id = []\n","    first_sentence = True\n","    sentence_start = True\n","    for token in padded_sentence:\n","      if first_sentence and sentence_start and token == 0:\n","        # Allows 0 at the start of the first sentence\n","        token_type_id.append(0)\n","      elif first_sentence and token > 0:\n","        if sentence_start:\n","          sentence_start = False\n","        token_type_id.append(0)\n","      elif first_sentence and not sentence_start and token == 0:\n","        first_sentence = False\n","        # Start of second sentence\n","        token_type_id.append(1)\n","      else:\n","        # Second sentence\n","        token_type_id.append(1)\n","    wic_padded[\"token_type_ids\"].append(token_type_id)\n","  if testing:\n","    if shuffle_data:\n","      # Shuffle the data\n","      raw_set = {\"input_ids\": [], \"token_type_ids\": [], \"attention_mask\": [], \"labels\": [], \"word1_locs\": [], \"word2_locs\" : []}\n","      raw_set[\"input_ids\"], raw_set[\"token_type_ids\"], raw_set[\"attention_mask\"], raw_set[\"labels\"] = shuffle(wic_padded[\"input_ids\"], wic_padded[\"token_type_ids\"],\n","                                                                                                              wic_padded[\"attention_mask\"], wic_labels,\n","                                                                                                              wic_padded[\"word1_locs\"], wic_padded[\"word2_locs\"])\n","    else:\n","      raw_set = {\"input_ids\": wic_padded[\"input_ids\"], \"token_type_ids\": wic_padded[\"token_type_ids\"],\n","                 \"attention_mask\": wic_padded[\"attention_mask\"], \"labels\": wic_labels,\n","                 \"word1_locs\": wic_padded[\"word1_locs\"], \"word2_locs\" : wic_padded[\"word2_locs\"]}\n","  else: # No labels present (Testing set)\n","    # Do not shuffle the testing set\n","    raw_set = {\"input_ids\": wic_padded[\"input_ids\"], \"token_type_ids\": wic_padded[\"token_type_ids\"], \n","               \"attention_mask\": wic_padded[\"attention_mask\"], \n","               \"word1_locs\": wic_padded[\"word1_locs\"], \"word2_locs\" : wic_padded[\"word2_locs\"]}\n","  # Return the raw data (Need to put them in a PyTorch tensor and dataset)\n","  return raw_set"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8xfpA0yDbp-w","colab_type":"text"},"source":["# Training and Validation"]},{"cell_type":"markdown","metadata":{"id":"FcdSSWXkhOmv","colab_type":"text"},"source":["## Constants and Hyperparameters \n","(should probably make a separate one for each training model in the sections below)"]},{"cell_type":"code","metadata":{"id":"xwNPw0J6r6c1","colab_type":"code","outputId":"1d74e148-8d00-4912-eed8-47493272f914","executionInfo":{"status":"ok","timestamp":1574998736318,"user_tz":300,"elapsed":1904,"user":{"displayName":"Simon Fortier-Garceau","photoUrl":"","userId":"08177308718689968362"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["BATCH_SIZE = 64\n","PATIENCE = 5\n","\n","# INSTANTIATE THE VOCABULARY\n","SEMCOR_VOCAB = SemCor_SensEval_Vocab()\n","\n","# Prepare Torch to use GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","print(torch.cuda.get_device_name(0))\n","\n","#UTILITY F?UNCTIONS\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Tesla K80\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"STowhUF5gf9K","colab_type":"text"},"source":["## Load the RoBERTa model"]},{"cell_type":"code","metadata":{"id":"RxGfvKkdvAvs","colab_type":"code","outputId":"a3a44c40-e5ae-4419-f444-5f9612ab02c4","executionInfo":{"status":"ok","timestamp":1574998768900,"user_tz":300,"elapsed":30746,"user":{"displayName":"Simon Fortier-Garceau","photoUrl":"","userId":"08177308718689968362"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["#roberta_model = RobertaModel.from_pretrained('roberta-base') # Working without Masked LM (shouldn't use if LM is good)\n","# https://huggingface.co/transformers/_modules/transformers/modeling_roberta.html#RobertaForMaskedLM\n","roberta_model = RobertaForMaskedLM.from_pretrained('roberta-base') # Working with Masked LM\n","roberta_model.to(device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 473/473 [00:00<00:00, 88598.87B/s]\n","100%|██████████| 501200538/501200538 [00:15<00:00, 31530650.68B/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["RobertaForMaskedLM(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n","      (position_embeddings): Embedding(514, 768)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (lm_head): RobertaLMHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    (decoder): Linear(in_features=768, out_features=50265, bias=False)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"_OGTh5f3b3i3","colab_type":"text"},"source":["## SemCor/SensEval Training and Validation"]},{"cell_type":"markdown","metadata":{"id":"eLaVHJ-YcCwB","colab_type":"text"},"source":["### Load the SemCor/SensEval data"]},{"cell_type":"code","metadata":{"id":"vbRM7cbSksuk","colab_type":"code","outputId":"c7bff533-ed5c-4397-fe24-bb867b48e523","executionInfo":{"status":"ok","timestamp":1574998777562,"user_tz":300,"elapsed":5835,"user":{"displayName":"Simon Fortier-Garceau","photoUrl":"","userId":"08177308718689968362"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["raw_train_set = load_json_objects_from_file(\"/content/drive/My Drive/CSI5138_Project/SensEval/preprocessed_semcor.jsonl\")\n","raw_eval_set = load_json_objects_from_file(\"/content/drive/My Drive/CSI5138_Project/SensEval/preprocessed_senseval.jsonl\")\n","\n","print(len(raw_eval_set[0][0]))\n","print(len(raw_train_set[0][0]))\n","print(raw_eval_set[5][0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["151\n","151\n","[[1, 1], [2, 3], [4, 4], [5, 5], [6, 6], [7, 7], [8, 8], [9, 9], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1], [-1, -1]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dyOAn1xxwuO_","colab_type":"code","outputId":"937d72a2-a4e9-41da-8f4c-6d2d9616b6c2","executionInfo":{"status":"error","timestamp":1574899323569,"user_tz":300,"elapsed":611,"user":{"displayName":"Simon Fortier-Garceau","photoUrl":"","userId":"08177308718689968362"}},"colab":{"base_uri":"https://localhost:8080/","height":282}},"source":["#TESTS\n","#print(raw_eval_set[0][0]) #token_ids\n","#print(tokenizer.convert_ids_to_tokens(raw_train_set[0][0])) #tokens\n","#print(raw_eval_set[1][0]) #attention_mask\n","#print(raw_eval_set[2][0]) #sense_ids\n","#print(raw_eval_set[3][0]) #pos_ids\n","#print(raw_eval_set[4][0]) #lemma_ids\n","#print(raw_eval_set[5][0]) #emb_intervals\n","print(raw_eval_set[6][0]) #words in the sentence\n","\n","print(SEMCOR_VOCAB.convertListSenseID_to_Sense(raw_eval_set[2][0]))\n","\n","wordIndices = SEMCOR_VOCAB.getIndicesOfWords(raw_eval_set[6][0])\n","#for j in range(0,10):\n","#  print(raw_eval_set[7][j]) \n","#print(wordIndices)\n","\n","print(SEMCOR_VOCAB.SENSESPACES[wordIndices[6]])\n","print(raw_eval_set[7][0]) #senseSpaceIDs in the sentence\n","\n","\n","#print(SEMCOR_VOCAB.convertListPOSID_to_POS(raw_eval_set[3][0]))\n","#print(SEMCOR_VOCAB.convertListLemmaID_to_Lemma(raw_eval_set[4][0]))\n","#check for the largest space in SENSESPACES:\n","maximum = 0\n","\n","for space in SEMCOR_VOCAB.SENSESPACES:\n","  if len(space) > maximum:\n","    maximum = len(space)\n","\n","maximum\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[11497, 14403, 10347, 2380, 22201, 5898, 4082, 17627, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-3b824a79760d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_eval_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#words in the sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEMCOR_VOCAB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvertListSenseID_to_Sense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_eval_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwordIndices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSEMCOR_VOCAB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetIndicesOfWords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_eval_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'SEMCOR_VOCAB' is not defined"]}]},{"cell_type":"code","metadata":{"id":"euNaLotEsh3i","colab_type":"code","colab":{}},"source":["# Combine the two loaded datasets into one\n","raw_train_set[0] = raw_train_set[0] + raw_eval_set[0]\n","raw_train_set[1] = raw_train_set[1] + raw_eval_set[1]\n","raw_train_set[2] = raw_train_set[2] + raw_eval_set[2]\n","raw_train_set[3] = raw_train_set[3] + raw_eval_set[3]\n","raw_train_set[4] = raw_train_set[4] + raw_eval_set[4]\n","raw_train_set[5] = raw_train_set[5] + raw_eval_set[5]\n","raw_train_set[7] = raw_train_set[7] + raw_eval_set[7] #these give you the position of the senses in a space of size 31\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gxrwe-QtR8oQ","colab_type":"code","colab":{}},"source":["# Create a PyTorch dataset for training and evaluation sets for senses and POS\n","train_data = TensorDataset(\n","    torch.tensor(raw_train_set[0]), #token_ids\n","    torch.tensor(raw_train_set[1]), #attention_mask\n","    torch.tensor(raw_train_set[2]), #sense_ids\n","    torch.tensor(raw_train_set[3]), #pos_ids\n","    torch.tensor(raw_train_set[4]), #lemma_ids\n","    torch.tensor(raw_train_set[5]), #emb_intervals\n","    torch.tensor(raw_train_set[7]), #sense_spaceids\n",")\n","\n","# Shuffle and split the data as seen in the link below to split into train/validation sets\n","# https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets\n","validation_split = 0.15 # 15% validation, 85% training\n","indices = list(range(len(train_data)))\n","split_point = int(np.floor(validation_split * len(train_data)))\n","np.random.seed(1) # For reproducability\n","np.random.shuffle(indices) # Shuffle the indices\n","\n","train_indices, validation_indices = indices[split_point:], indices[:split_point]\n","\n","# Create a sampler and loader for the train and validation sets\n","train_sampler = SubsetRandomSampler(train_indices)\n","validation_sampler = SubsetRandomSampler(validation_indices)\n","\n","trainloader = DataLoader(train_data, sampler=train_sampler, batch_size=1)\n","validationloader = DataLoader(train_data, sampler=validation_sampler, batch_size=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iFQA2tDQt4yF","colab_type":"code","colab":{}},"source":["# ISSUE: tokenizer not containing the function get_special_tokens_mask which means that we may be\n","# using an older version (see second commented link)\n","# \n","# Taken directly from an official example on the library's Github:\n","# https://github.com/huggingface/transformers/blob/master/examples/run_lm_finetuning.py\n","# https://github.com/huggingface/transformers/releases\n","# https://huggingface.co/transformers/model_doc/roberta.html\n","# https://github.com/pytorch/fairseq/tree/master/examples/roberta\n","def mask_tokens(inputs, tokenizer, probability=0.15):\n","    \"\"\" Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. \"\"\"\n","    labels = inputs.clone()\n","    # We sample a few tokens in each sequence for masked-LM training (with probability defaulting to 0.15 in Bert/RoBERTa)\n","    probability_matrix = torch.full(labels.shape, probability)\n","    special_tokens_mask = [list(map(lambda x: 1 if x in [tokenizer.sep_token_id, tokenizer.cls_token_id] else 0, val)) for val in labels.tolist()]\n","    probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\n","    masked_indices = torch.bernoulli(probability_matrix).bool().cuda()\n","    labels[~masked_indices] = -1  # We only compute loss on masked tokens\n","    # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\n","    indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool().cuda() & masked_indices\n","    inputs[indices_replaced] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n","\n","    # 10% of the time, we replace masked input tokens with random word\n","    indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool().cuda() & masked_indices & ~indices_replaced\n","    random_words = torch.randint(len(tokenizer), labels.shape, dtype=torch.long).cuda()\n","    inputs[indices_random] = random_words[indices_random]\n","\n","    # The rest of the time (10% of the time) we keep the masked input tokens unchanged\n","    return inputs, labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lUc8Rc9h0NRb","colab_type":"code","colab":{}},"source":["# Assumes a batch_size of one\n","# Given a RoBERTA model, embedding size, batch size, and output size, setup the fine-tuning for the senses of a word\n","class FineTuningHeadPOS(torch.nn.Module):\n","    # Setup the class by defining and storing any needed variables\n","    def __init__(self, output_size, batch_size=1, embedding_size=768):\n","        super(FineTuningHeadPOS, self).__init__()\n","        # The size of each contextual embedding\n","        self.embedding_size = embedding_size\n","        # The size of the output\n","        self.output_size = output_size\n","        # The batch size\n","        self.batch_size = batch_size\n","        # Define size of linear layers depending on if embedding_size > output_size or embedding_size < output_size\n","        # Should not be equal, but the layers would all be the same size if equal\n","        diff = abs(embedding_size - output_size)\n","        # Default is that the embedding_size is greater than the output_size\n","        sizes = [embedding_size - diff // 4, embedding_size - diff // 2]\n","        # If the embedding_size is less than the output size, we grow the valus appropriately\n","        if (embedding_size < output_size):\n","            sizes = [embedding_size + diff // 4, embedding_size + diff // 2]\n","        # Setup the layers for the MLP used to help learn the senses\n","        self.fcl1 = torch.nn.Linear(embedding_size, sizes[0])\n","        self.relu = torch.nn.ReLU()\n","        self.fcl2 = torch.nn.Linear(sizes[0], sizes[1])\n","        self.fcl3 = torch.nn.Linear(sizes[1], output_size)\n","        self.softmax = torch.nn.Softmax()\n","\n","    # Forward propagate with a sentence of words, one-by-one, learning to predict the\n","    # sense/POS/etc of a word.\n","    #\n","    # input_ids: The input ids for the embedding model to get embeddings per input\n","    # attention_mask: Used by the embedding model to help get the embeddings\n","    # embedding_intervals: The intervals for the embeddings specifying which embeddings to combine\n","    def forward(self, input_ids, attention_mask, embedding_intervals, embedding_model):\n","      \n","      extracted_emb = embExtract(embedding_model,input_ids,attention_mask, embedding_intervals)\n","      # For each embedding in other_embeddings, predict the related id from other_ids\n","      predictions = []\n","      for embedding in extracted_emb:\n","        output = self.relu(self.fcl1(embedding))\n","        output = self.relu(self.fcl2(output))\n","        output = self.fcl3(output)\n","        predictions.append(output)\n","            #predictions.append(output.view(-1, self.output_size))\n","            #predictions.append(torch.argmax(output))\n","      predictions = torch.stack(predictions)\n","      # Return the predictions, computing the loss in the training algorithm\n","      #return torch.stack([predictions])\n","      return predictions"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dio2rZtYNblO","colab_type":"code","colab":{}},"source":["# Assumes a batch_size of one\n","# Given a RoBERTA model, embedding size, batch size, and output size, setup the fine-tuning for the senses of a word\n","class FineTuningHeadSenses(torch.nn.Module):\n","    # Setup the class by defining and storing any needed variables\n","    def __init__(self, output_size=31, batch_size=1, embedding_size=768):\n","        super(FineTuningHeadSenses, self).__init__()\n","        # The size of each contextual embedding\n","        self.embedding_size = embedding_size\n","        # The size of the output\n","        self.output_size = output_size\n","        # The batch size\n","        self.batch_size = batch_size\n","        # Define size of linear layers depending on if embedding_size > output_size or embedding_size < output_size\n","        # Should not be equal, but the layers would all be the same size if equal\n","        diff = abs(embedding_size - output_size)\n","        # Default is that the embedding_size is greater than the output_size\n","        sizes = [embedding_size - diff // 4, embedding_size - diff // 2]\n","        # If the embedding_size is less than the output size, we grow the valus appropriately\n","        if (embedding_size < output_size):\n","            sizes = [embedding_size + diff // 4, embedding_size + diff // 2]\n","        # Setup the layers for the MLP used to help learn the senses\n","        self.fcl1 = torch.nn.Linear(embedding_size, sizes[0])\n","        self.relu = torch.nn.ReLU()\n","        self.fcl2 = torch.nn.Linear(sizes[0], sizes[1])\n","        self.fcl3 = torch.nn.Linear(sizes[1], output_size)\n","        self.softmax = torch.nn.Softmax()\n","\n","    # Forward propagate with a sentence of words, one-by-one, learning to predict the\n","    # sense/POS/etc of a word.\n","    #\n","    # input_ids: The input ids for the embedding model to get embeddings per input\n","    # attention_mask: Used by the embedding model to help get the embeddings\n","    # embedding_intervals: The intervals for the embeddings specifying which embeddings to combine\n","    def forward(self, input_ids, attention_mask, embedding_intervals, embedding_model):\n","        # Start by retrieving the embeddings from the embeddings model for input_ids and attention_mask\n","        extracted_emb = embExtract(embedding_model,input_ids, attention_mask, embedding_intervals)\n","          \n","        # For each embedding in other_embeddings, predict the related id from other_ids\n","        predictions = []\n","        for embedding in extracted_emb:\n","            output = self.relu(self.fcl1(embedding))\n","            output = self.relu(self.fcl2(output))\n","            output = self.fcl3(output)\n","            predictions.append(output)\n","            #predictions.append(output.view(-1, self.output_size))\n","            #predictions.append(torch.argmax(output))\n","        predictions = torch.stack(predictions)\n","        # Return the predictions, computing the loss in the training algorithm\n","        #return torch.stack([predictions])\n","        return predictions"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_XbZBKJQEHA7","colab_type":"code","colab":{}},"source":["# PARTIALLY COMPLETE (most likely need to modify how we use the loss, .item vs how it's set now)\n","# Did not specify the same optimizer setup as in the head, change if needed\n","\n","\n","min_loss = 99999999\n","\n","# Given a sense model and POS model, train them\n","def train_model(roberta_model, sense_model, pos_model, trainloader, validationloader, tokenizer, path, alpha_lm=1, alpha_sense=0.6, alpha_pos=0.4, lr=1e-5, epochs=5, fine_tune_RoBERTa = True):\n","    # Store the loss values found from the validation set\n","    val_losses = []\n","    mask_losses = []\n","    sense_losses = []\n","    pos_losses = []\n","    # Best loss and counter from when it was last set\n","    global min_loss\n","    since_last_min = 0\n","    early_stop = 10\n","    # Define the loss function\n","    loss_function = torch.nn.CrossEntropyLoss()\n","    # Optimizers for each model\n","    optimizers = [None, None, None]\n","    # Set to the GPU and setup the optimizers\n","    if sense_model is not None:\n","        optimizers[0] = torch.optim.Adam(sense_model.parameters(), lr)\n","    if pos_model is not None:\n","        optimizers[1] = torch.optim.Adam(pos_model.parameters(), lr)\n","\n","    optimizers[2] = torch.optim.Adam(roberta_model.parameters(), 1e-6)\n","\n","    # Train for the specified number of epochs\n","    \n","    #prevWeights1 = sense_model.fcl1.weight\n","    #prevWeights2 = sense_model.fcl2.weight    \n","\n","    epoch = 1\n","    iterations = 0\n","    validation_condition = len(trainloader) // 6\n","    while (epoch < epochs + 1):\n","        # Iterate through the instances in the train DataLoader\n","        for sample_set in trainloader:\n","            # Add batch to GPU\n","            sample_set = tuple(t.cuda() for t in sample_set)\n","            # Unpack the inputs from our dataloader\n","            input_ids, attention_mask, sense_ids, pos_ids, lemma_ids, embedding_intervals, sense_spaceids = sample_set\n","\n","\n","            #Keep track of the total number of samples for training\n","            totalNumSamples = len(trainloader)\n","\n","            \n","            #Want to train RoBERTa\n","            if fine_tune_RoBERTa:\n","              roberta_model.train()\n","            else:\n","              roberta_model.eval()\n","\n","\n","            # Masked LM training\n","            # TO DO: Review and edit this as needed\n","            loss_masked = torch.tensor(0.0)\n","            loss_masked = loss_masked.cuda()\n","            #'''\n","            inputs_masked, labels_masked = mask_tokens(input_ids, tokenizer)\n","            inputs_masked = inputs_masked.cuda()\n","            labels_masked = labels_masked.cuda()\n","            outputs_masked = roberta_model(inputs_masked, masked_lm_labels=labels_masked)\n","            loss_masked = outputs_masked[0]\n","            #'''\n","            # Train the sense model if it is provided\n","            loss_sense = torch.tensor(0.0)\n","            if sense_model is not None:            \n","              sense_model.train()\n","              optimizers[0].zero_grad()\n","              # Retrieve the sense predictions\n","              sense_predictions = sense_model(input_ids, attention_mask, embedding_intervals, roberta_model)\n","              sense_spaceids = torch.tensor([sense.view(-1) for sense in sense_spaceids.view(-1) if sense.item() != -1], dtype=torch.long)\n","              sense_spaceids = sense_spaceids.to(device)\n","              # Compute the loss for the sense predictions\n","              loss_sense = [loss_function(pred.view(1, -1), label.view(-1)) for pred, label in zip(sense_predictions, sense_spaceids)]\n","              loss_sense = torch.stack(loss_sense).sum() / len(loss_sense)\n","\n","                \n","            # Train the POS model if it is provided\n","            loss_pos = torch.tensor(0.0)\n","            if pos_model is not None:\n","              pos_model.train()\n","              optimizers[1].zero_grad()\n","              # Retrieve the POS predictions\n","              pos_predictions = pos_model(input_ids, attention_mask, embedding_intervals, roberta_model)\n","              pos_ids = torch.tensor([pos.view(-1) for pos in pos_ids.view(-1) if pos.item() != -1], dtype=torch.long)\n","              pos_ids = pos_ids.cuda()\n","              # Computer the loss for the POS predictions\n","              loss_pos = [loss_function(pred.view(1, -1), label.view(-1)) for pred, label in zip(pos_predictions, pos_ids)]\n","              loss_pos = torch.stack(loss_pos).sum() / len(loss_pos)              \n","              \n","\n","\n","            optimizers[2].zero_grad()\n","            #total_loss = torch.autograd.Variable(alpha_lm * loss_masked + alpha_sense * loss_sense + alpha_pos * loss_pos, requires_grad=True)\n","            total_loss = alpha_lm * loss_masked + alpha_sense * loss_sense + alpha_pos * loss_pos\n","            total_loss.backward()\n","\n","            for optimizer in optimizers:\n","              if optimizer != None:\n","                optimizer.step()\n","\n","\n","            #Get statistics\n","            if iterations%5 == 0:\n","              #print(roberta_model.fcl1.weight)\n","              print(\"Training Losses: \", \"- Iter:\", iterations, \"/\",totalNumSamples, \"- Masked LM=\", loss_masked.item(), \"- Sense=\", loss_sense.item(), \"- POS=\", loss_pos.item(), \"- TOTAL=\", total_loss.item())\n","              print('Iteration:',iterations)\n","              #print(roberta_model.encoder.layer[1].intermediate.dense.weight)\n","              \n","              #currentWeights1 = sense_model.fcl1.weight\n","              #currentWeights2 = sense_model.fcl2.weight\n","              #print('Weights1Compare', currentWeights1 == sense_model.fcl1.weight)\n","              #print('Weights2Compare', currentWeights2 == sense_model.fcl2.weight)\n","              #prevWeights1 = currentWeights1\n","              #prevWeights2 = currentWeights2\n","\n","              #print(pos_model.fcl1.weight)\n","              #print(pos_model.fcl2.weight)\n","              #print(pos_model.fcl3.weight)\n","            \n","            # Test on the validation set if the validation condition is met\n","            if (iterations % validation_condition == 0):\n","              total_loss, loss_mask, loss_sense, loss_pos = test_model(roberta_model, sense_model, pos_model, validationloader, tokenizer, alpha_lm, alpha_sense, alpha_pos)\n","              val_losses.append(total_loss)\n","              mask_losses.append(loss_mask)\n","              sense_losses.append(loss_sense)\n","              pos_losses.append(loss_pos)\n","              print(\"Iteration\", iterations, \"- Validation Loss=\", total_loss)\n","              # Early stopping check\n","              if (min_loss >= total_loss):                \n","                min_loss = total_loss\n","\n","                #Create pathname for the RoBERTa model folder\n","                #RoBERTaPath = path + \"/RoBERTa\"                 \n","\n","                #Save each model to the specified path (and create one if it does not exist)\n","                #REMARK: os is imported at the top of the notebook\n","                #if not os.path.exists(RoBERTaPath):\n","                 # os.makedirs(RoBERTaPath)\n","                #roberta_model.save_pretrained(RoBERTaPath)\n","                #if sense_model != None:\n","                #  torch.save(sense_model.state_dict(), path + '/SenseModel.pt')\n","                #if pos_model != None:\n","                #  torch.save(pos_model.state_dict(), path + '/PosModel.pt') \n","\n","                since_last_min = 0\n","\n","              else:\n","                since_last_min += 1\n","              if (since_last_min >= early_stop):\n","                epoch = max_epoch\n","                break\n","            iterations += 1\n","        epoch += 1\n","\n","    return val_losses, mask_losses, sense_losses, pos_losses"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UBdpNV024S7h","colab_type":"code","colab":{}},"source":["# Test the model with a given dataloader\n","def test_model(roberta_model, sense_model, pos_model, dataloader, tokenizer, alpha_lm=1, alpha_sense=0.6, alpha_pos=0.4):\n","    # Store the values to return\n","    loss_values = [[], [], [], []] # 0 (total), 1 (mask), 2 (sense), 3 (pos)\n","    # Define the loss function\n","    loss_function = torch.nn.CrossEntropyLoss()    \n","    roberta_model.eval()\n","\n","    if sense_model is not None:\n","        sense_model.eval()\n","    if pos_model is not None:\n","        pos_model.eval()\n","\n","    correct_sense = 0\n","    total_sense = 0\n","    correct_pos = 0\n","    total_pos = 0\n","\n","    with torch.no_grad():\n","        for i, sample_set in enumerate(dataloader):\n","\n","            #Keep tack of total number of samples for testing\n","            totalNumSamples = len(dataloader)\n","\n","            if i%100 == 0:\n","              print(\"Testing sample:\", i , \"/\", totalNumSamples)\n","            # Add batch to GPU\n","            sample_set = tuple(t.cuda() for t in sample_set)\n","            # Unpack the inputs from our dataloader\n","            input_ids, attention_mask, sense_ids, pos_ids, lemma_ids, embedding_intervals, sense_spaceids = sample_set\n","            # Masked LM training\n","            # TO DO: Review and edit this as needed\n","            loss_masked = torch.tensor(0.0)\n","            loss_masked = loss_masked.cuda()\n","            #'''\n","            inputs_masked, labels_masked = mask_tokens(input_ids, tokenizer)\n","            inputs_masked = inputs_masked.cuda()\n","            labels_masked = labels_masked.cuda()\n","            outputs_masked = roberta_model(inputs_masked, masked_lm_labels=labels_masked)\n","            loss_masked = outputs_masked[0].item()\n","            #'''\n","            loss_values[1].append(loss_masked)\n","            # Train the sense model if it is provided\n","            loss_sense = 0.0\n","            if sense_model is not None:\n","                # Retrieve the sense predictions\n","                sense_predictions = sense_model(input_ids, attention_mask, embedding_intervals, roberta_model)\n","                sense_spaceids = torch.tensor([sense.view(-1) for sense in sense_spaceids.view(-1) if sense.item() != -1], dtype=torch.long)\n","                sense_spaceids = sense_spaceids.cuda()\n","\n","                for pred, label in zip(sense_predictions, sense_spaceids):\n","                  pred_actual = torch.argmax(torch.tensor(torch.nn.functional.softmax(pred)))\n","                  if (pred_actual.view(-1).item() == label.view(-1).item()):\n","                    correct_sense += 1\n","                  total_sense += 1\n","\n","                # Compute the loss for the sense predictions\n","                loss_sense = [loss_function(pred.view(1, -1), label.view(-1)).item() for pred, label in zip(sense_predictions, sense_spaceids)]\n","                loss_sense = sum(loss_sense) / len(loss_sense)\n","                loss_values[2].append(loss_sense)\n","            # Train the POS model if it is provided\n","            loss_pos = 0.0\n","            if pos_model is not None:\n","                # Retrieve the POS predictions\n","                pos_predictions = pos_model(input_ids, attention_mask, embedding_intervals, roberta_model)\n","                pos_ids = torch.tensor([pos.view(-1) for pos in pos_ids.view(-1) if pos.item() != -1], dtype=torch.long)\n","                pos_ids = pos_ids.cuda()\n","\n","                for pred, label in zip(pos_predictions, pos_ids):\n","                  pred_actual = torch.argmax(torch.tensor(torch.nn.functional.softmax(pred)))\n","                  if (pred_actual.view(-1).item() == label.view(-1).item()):\n","                    correct_pos += 1\n","                  total_pos += 1\n","\n","\n","                # Computer the loss for the POS predictions\n","                loss_pos = [loss_function(pred.view(1, -1), label.view(-1)).item() for pred, label in zip(pos_predictions, pos_ids)]\n","                loss_pos = sum(loss_pos) / len(loss_pos)\n","                loss_values[3].append(loss_pos)\n","            loss_values[0].append(alpha_lm * loss_masked + alpha_sense * loss_sense + alpha_pos * loss_pos)\n","            #print(alpha_lm * loss_masked + alpha_sense * loss_sense + alpha_pos * loss_pos)\n","            #print(loss_masked)\n","            #print(loss_sense)\n","            #print(loss_pos)\n","    # Average the loss and return them\n","    loss_averages = []\n","    for loss_list in loss_values:\n","        avg = 0\n","        if len(loss_list) > 0:\n","            avg = sum(loss_list) / len(loss_list)\n","        loss_averages.append(avg)\n","    if sense_model is not None:\n","        print(\"Sense Accuracy =\", correct_sense / total_sense)\n","    if pos_model is not None:\n","        print(\"POS Accuracy =\", correct_pos / total_pos)\n","    return loss_averages[0], loss_averages[1], loss_averages[2], loss_averages[3]\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_2k_qEPU2_4Y","colab_type":"code","outputId":"38a88a97-6254-449c-a063-410af9e99111","executionInfo":{"status":"ok","timestamp":1574998809433,"user_tz":300,"elapsed":2605,"user":{"displayName":"Simon Fortier-Garceau","photoUrl":"","userId":"08177308718689968362"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#PUT YOUR NAME FOR THE FOLDER HERE!!!\n","NAME = 'Common'\n","basepath = f\"/content/drive/My Drive/CSI5138_Project/Models/{NAME}\" \n","\n","# Define the model used for senses\n","# Note that for POS, we would simply need to change the output size.\n","output_size = 31\n","#sense_model = None\n","sense_model = FineTuningHeadSenses(output_size, batch_size=1, embedding_size=768)\n","\n","if sense_model != None:\n","  if os.path.exists(basepath + '/SenseModel.pt'):\n","    sense_model.load_state_dict(torch.load(basepath + '/SenseModel.pt'))\n","    print('Sense loaded')\n","  sense_model.to(device)\n","\n","output_size = len(SEMCOR_VOCAB.POS)\n","#pos_model = None\n","pos_model = FineTuningHeadPOS(output_size, batch_size=1, embedding_size=768)\n","\n","if pos_model != None:\n","  if os.path.exists(basepath + '/PosModel.pt'):\n","    pos_model.load_state_dict(torch.load(basepath + '/PosModel.pt'))\n","    print('POS loaded')\n","  pos_model.to(device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sense loaded\n","POS loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lp8wifyQ6y9J","colab_type":"code","outputId":"fe72e0fe-5094-47dd-8cce-3c8d87fab98b","executionInfo":{"status":"ok","timestamp":1574911452805,"user_tz":300,"elapsed":2152189,"user":{"displayName":"Simon Fortier-Garceau","photoUrl":"","userId":"08177308718689968362"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","ALPHA_LM = 0.75\n","ALPHA_SENSE = 0.15\n","ALPHA_POS = 0.10\n","LR = 1e-4\n","EPOCHS = 5\n","FINE_TUNE_ROBERTA = True\n","\n","\n","#IMPORTANT REMARK: It takes about 2 minutes for the folders and saved models to appear in google drive, give it some time before doing anything else\n","val_losses, mask_losses, sense_losses, pos_losses = train_model(roberta_model, sense_model, \n","                                                                pos_model, trainloader, validationloader, \n","                                                                tokenizer, basepath, alpha_lm=ALPHA_LM, alpha_sense=ALPHA_SENSE, \n","                                                                alpha_pos=ALPHA_POS, lr=LR, epochs=EPOCHS, fine_tune_RoBERTa = FINE_TUNE_ROBERTA)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training Losses:  - Iter: 0 / 9962 - Masked LM= 17.55171775817871 - Sense= 0.48889297246932983 - POS= 0.14243881404399872 - TOTAL= 13.251365661621094\n","Iteration: 0\n","Testing sample: 0 / 1758\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"],"name":"stderr"},{"output_type":"stream","text":["Testing sample: 100 / 1758\n","Testing sample: 200 / 1758\n","Testing sample: 300 / 1758\n","Testing sample: 400 / 1758\n","Testing sample: 500 / 1758\n","Testing sample: 600 / 1758\n","Testing sample: 700 / 1758\n","Testing sample: 800 / 1758\n","Testing sample: 900 / 1758\n","Testing sample: 1000 / 1758\n","Testing sample: 1100 / 1758\n","Testing sample: 1200 / 1758\n","Testing sample: 1300 / 1758\n","Testing sample: 1400 / 1758\n","Testing sample: 1500 / 1758\n","Testing sample: 1600 / 1758\n","Testing sample: 1700 / 1758\n","Sense Accuracy = 0.8276276108566961\n","POS Accuracy = 0.8890316095163632\n","Iteration 0 - Validation Loss= 8.157491491729212\n","Training Losses:  - Iter: 5 / 9962 - Masked LM= 5.768526077270508 - Sense= 0.42209240794181824 - POS= 1.2897332906723022 - TOTAL= 4.51868200302124\n","Iteration: 5\n","Training Losses:  - Iter: 10 / 9962 - Masked LM= 31.260534286499023 - Sense= 0.01658022403717041 - POS= 0.9297407269477844 - TOTAL= 23.540861129760742\n","Iteration: 10\n","Training Losses:  - Iter: 15 / 9962 - Masked LM= 4.154908180236816 - Sense= 0.7643370628356934 - POS= 0.773841381072998 - TOTAL= 3.308215856552124\n","Iteration: 15\n","Training Losses:  - Iter: 20 / 9962 - Masked LM= 6.835752964019775 - Sense= 1.3550045490264893 - POS= 0.2171984165906906 - TOTAL= 5.351785659790039\n","Iteration: 20\n","Training Losses:  - Iter: 25 / 9962 - Masked LM= 6.138147830963135 - Sense= 0.54891037940979 - POS= 0.5558450818061829 - TOTAL= 4.741531848907471\n","Iteration: 25\n","Training Losses:  - Iter: 30 / 9962 - Masked LM= 9.119327545166016 - Sense= 0.908478319644928 - POS= 0.3904735743999481 - TOTAL= 7.014814853668213\n","Iteration: 30\n","Training Losses:  - Iter: 35 / 9962 - Masked LM= 7.198690891265869 - Sense= 0.4401642084121704 - POS= 0.7837481498718262 - TOTAL= 5.543417930603027\n","Iteration: 35\n","Training Losses:  - Iter: 40 / 9962 - Masked LM= 0.0 - Sense= 0.3129124343395233 - POS= 0.06969613581895828 - TOTAL= 0.053906477987766266\n","Iteration: 40\n","Training Losses:  - Iter: 45 / 9962 - Masked LM= 9.927668571472168 - Sense= 0.1235208734869957 - POS= 0.4375501573085785 - TOTAL= 7.5080342292785645\n","Iteration: 45\n","Training Losses:  - Iter: 50 / 9962 - Masked LM= 0.0 - Sense= 0.2927458882331848 - POS= 0.2336130142211914 - TOTAL= 0.06727318465709686\n","Iteration: 50\n","Training Losses:  - Iter: 55 / 9962 - Masked LM= 5.785747528076172 - Sense= 0.36965829133987427 - POS= 0.15291579067707062 - TOTAL= 4.410050868988037\n","Iteration: 55\n","Training Losses:  - Iter: 60 / 9962 - Masked LM= 6.218686580657959 - Sense= 0.1743258684873581 - POS= 0.4867785573005676 - TOTAL= 4.738841533660889\n","Iteration: 60\n","Training Losses:  - Iter: 65 / 9962 - Masked LM= 7.644028663635254 - Sense= 0.8135223388671875 - POS= 0.548435628414154 - TOTAL= 5.90989351272583\n","Iteration: 65\n","Training Losses:  - Iter: 70 / 9962 - Masked LM= 6.037984371185303 - Sense= 0.8861362338066101 - POS= 0.11330123990774155 - TOTAL= 4.672738552093506\n","Iteration: 70\n","Training Losses:  - Iter: 75 / 9962 - Masked LM= 6.907456874847412 - Sense= 0.46757227182388306 - POS= 0.27922046184539795 - TOTAL= 5.278650760650635\n","Iteration: 75\n","Training Losses:  - Iter: 80 / 9962 - Masked LM= 5.957501411437988 - Sense= 0.6576560139656067 - POS= 0.03048928640782833 - TOTAL= 4.569823741912842\n","Iteration: 80\n","Training Losses:  - Iter: 85 / 9962 - Masked LM= 6.826380252838135 - Sense= 0.8711772561073303 - POS= 0.5850527882575989 - TOTAL= 5.308967113494873\n","Iteration: 85\n","Training Losses:  - Iter: 90 / 9962 - Masked LM= 0.0 - Sense= 0.40119093656539917 - POS= 0.005206306930631399 - TOTAL= 0.06069927290081978\n","Iteration: 90\n","Training Losses:  - Iter: 95 / 9962 - Masked LM= 0.0 - Sense= 0.016908764839172363 - POS= 0.2840532064437866 - TOTAL= 0.030941637232899666\n","Iteration: 95\n","Training Losses:  - Iter: 100 / 9962 - Masked LM= 6.588039398193359 - Sense= 0.4940985441207886 - POS= 0.6674415469169617 - TOTAL= 5.081888675689697\n","Iteration: 100\n","Training Losses:  - Iter: 105 / 9962 - Masked LM= 5.354165077209473 - Sense= 0.3309657573699951 - POS= 0.053495921194553375 - TOTAL= 4.070618629455566\n","Iteration: 105\n","Training Losses:  - Iter: 110 / 9962 - Masked LM= 6.138270378112793 - Sense= 0.3228042721748352 - POS= 0.295377641916275 - TOTAL= 4.6816606521606445\n","Iteration: 110\n","Training Losses:  - Iter: 115 / 9962 - Masked LM= 5.303205966949463 - Sense= 0.5702486634254456 - POS= 0.14641745388507843 - TOTAL= 4.0775837898254395\n","Iteration: 115\n","Training Losses:  - Iter: 120 / 9962 - Masked LM= 4.480020999908447 - Sense= 0.2961859107017517 - POS= 0.16131004691123962 - TOTAL= 3.42057466506958\n","Iteration: 120\n","Training Losses:  - Iter: 125 / 9962 - Masked LM= 3.7109482288360596 - Sense= 0.7724961638450623 - POS= 0.1521390974521637 - TOTAL= 2.914299726486206\n","Iteration: 125\n","Training Losses:  - Iter: 130 / 9962 - Masked LM= 0.0 - Sense= 0.5326772332191467 - POS= 0.008018195629119873 - TOTAL= 0.08070340752601624\n","Iteration: 130\n","Training Losses:  - Iter: 135 / 9962 - Masked LM= 4.137862682342529 - Sense= 0.8785513043403625 - POS= 0.23617242276668549 - TOTAL= 3.2587969303131104\n","Iteration: 135\n","Training Losses:  - Iter: 140 / 9962 - Masked LM= 5.993005275726318 - Sense= 0.4938823878765106 - POS= 0.24173322319984436 - TOTAL= 4.5930094718933105\n","Iteration: 140\n","Training Losses:  - Iter: 145 / 9962 - Masked LM= 7.840210914611816 - Sense= 0.31633028388023376 - POS= 0.2789528965950012 - TOTAL= 5.955503463745117\n","Iteration: 145\n","Training Losses:  - Iter: 150 / 9962 - Masked LM= 5.1314592361450195 - Sense= 0.4619241952896118 - POS= 0.2072005718946457 - TOTAL= 3.938603162765503\n","Iteration: 150\n","Training Losses:  - Iter: 155 / 9962 - Masked LM= 0.0 - Sense= 0.49741870164871216 - POS= 0.2192094922065735 - TOTAL= 0.09653376042842865\n","Iteration: 155\n","Training Losses:  - Iter: 160 / 9962 - Masked LM= 4.598651885986328 - Sense= 0.6001331210136414 - POS= 0.21925291419029236 - TOTAL= 3.560934066772461\n","Iteration: 160\n","Training Losses:  - Iter: 165 / 9962 - Masked LM= 5.456214904785156 - Sense= 0.6506709456443787 - POS= 0.07014208287000656 - TOTAL= 4.196775913238525\n","Iteration: 165\n","Training Losses:  - Iter: 170 / 9962 - Masked LM= 3.405099391937256 - Sense= 0.48723089694976807 - POS= 0.38473057746887207 - TOTAL= 2.665382146835327\n","Iteration: 170\n","Training Losses:  - Iter: 175 / 9962 - Masked LM= 7.608102321624756 - Sense= 0.806494414806366 - POS= 0.40221357345581055 - TOTAL= 5.867271900177002\n","Iteration: 175\n","Training Losses:  - Iter: 180 / 9962 - Masked LM= 6.705778121948242 - Sense= 0.017277559265494347 - POS= 0.4645550847053528 - TOTAL= 5.078380584716797\n","Iteration: 180\n","Training Losses:  - Iter: 185 / 9962 - Masked LM= 7.843207836151123 - Sense= 0.6864799857139587 - POS= 0.051600802689790726 - TOTAL= 5.990537643432617\n","Iteration: 185\n","Training Losses:  - Iter: 190 / 9962 - Masked LM= 4.506762981414795 - Sense= 0.5049456357955933 - POS= 0.22921256721019745 - TOTAL= 3.4787352085113525\n","Iteration: 190\n","Training Losses:  - Iter: 195 / 9962 - Masked LM= 4.106803894042969 - Sense= 0.3075202703475952 - POS= 0.3483162820339203 - TOTAL= 3.161062479019165\n","Iteration: 195\n","Training Losses:  - Iter: 200 / 9962 - Masked LM= 7.768716335296631 - Sense= 0.05330370366573334 - POS= 0.5395568609237671 - TOTAL= 5.888488292694092\n","Iteration: 200\n","Training Losses:  - Iter: 205 / 9962 - Masked LM= 0.0 - Sense= 0.16719898581504822 - POS= 0.05209016799926758 - TOTAL= 0.03028886578977108\n","Iteration: 205\n","Training Losses:  - Iter: 210 / 9962 - Masked LM= 6.4670586585998535 - Sense= 0.27853167057037354 - POS= 0.23489905893802643 - TOTAL= 4.915563583374023\n","Iteration: 210\n","Training Losses:  - Iter: 215 / 9962 - Masked LM= 6.317530155181885 - Sense= 0.33458757400512695 - POS= 1.3042384386062622 - TOTAL= 4.918759822845459\n","Iteration: 215\n","Training Losses:  - Iter: 220 / 9962 - Masked LM= 7.193126678466797 - Sense= 0.195074200630188 - POS= 0.5277411341667175 - TOTAL= 5.476880073547363\n","Iteration: 220\n","Training Losses:  - Iter: 225 / 9962 - Masked LM= 7.017485618591309 - Sense= 0.12269660085439682 - POS= 0.07577583938837051 - TOTAL= 5.289095878601074\n","Iteration: 225\n","Training Losses:  - Iter: 230 / 9962 - Masked LM= 3.0883729457855225 - Sense= 0.3489782512187958 - POS= 0.07049242407083511 - TOTAL= 2.375675678253174\n","Iteration: 230\n","Training Losses:  - Iter: 235 / 9962 - Masked LM= 3.2968034744262695 - Sense= 0.12119773030281067 - POS= 0.32250168919563293 - TOTAL= 2.5230324268341064\n","Iteration: 235\n","Training Losses:  - Iter: 240 / 9962 - Masked LM= 5.768256187438965 - Sense= 0.5409823060035706 - POS= 0.2665228545665741 - TOTAL= 4.433991432189941\n","Iteration: 240\n","Training Losses:  - Iter: 245 / 9962 - Masked LM= 4.2333574295043945 - Sense= 0.1977802813053131 - POS= 0.10299038141965866 - TOTAL= 3.214984178543091\n","Iteration: 245\n","Training Losses:  - Iter: 250 / 9962 - Masked LM= 3.052098274230957 - Sense= 0.4459085166454315 - POS= 0.12048784643411636 - TOTAL= 2.368008613586426\n","Iteration: 250\n","Training Losses:  - Iter: 255 / 9962 - Masked LM= 5.801713466644287 - Sense= 0.7898792624473572 - POS= 0.25749561190605164 - TOTAL= 4.495516777038574\n","Iteration: 255\n","Training Losses:  - Iter: 260 / 9962 - Masked LM= 0.0 - Sense= 0.03170657157897949 - POS= 0.03733029216527939 - TOTAL= 0.008489015512168407\n","Iteration: 260\n","Training Losses:  - Iter: 265 / 9962 - Masked LM= 7.344113826751709 - Sense= 0.6792703866958618 - POS= 0.6302362084388733 - TOTAL= 5.672999382019043\n","Iteration: 265\n","Training Losses:  - Iter: 270 / 9962 - Masked LM= 3.4093120098114014 - Sense= 0.39814433455467224 - POS= 0.2658473253250122 - TOTAL= 2.6432902812957764\n","Iteration: 270\n","Training Losses:  - Iter: 275 / 9962 - Masked LM= 2.724468231201172 - Sense= 0.4853651225566864 - POS= 0.3419911563396454 - TOTAL= 2.1503548622131348\n","Iteration: 275\n","Training Losses:  - Iter: 280 / 9962 - Masked LM= 4.046597480773926 - Sense= 1.2584731578826904 - POS= 0.6197599768638611 - TOTAL= 3.2856950759887695\n","Iteration: 280\n","Training Losses:  - Iter: 285 / 9962 - Masked LM= 0.0 - Sense= 0.0030405521392822266 - POS= 0.028620421886444092 - TOTAL= 0.0033181251492351294\n","Iteration: 285\n","Training Losses:  - Iter: 290 / 9962 - Masked LM= 3.9909636974334717 - Sense= 0.34838971495628357 - POS= 0.18414825201034546 - TOTAL= 3.0638959407806396\n","Iteration: 290\n","Training Losses:  - Iter: 295 / 9962 - Masked LM= 3.487335205078125 - Sense= 0.3239915370941162 - POS= 0.03638004511594772 - TOTAL= 2.667738199234009\n","Iteration: 295\n","Training Losses:  - Iter: 300 / 9962 - Masked LM= 4.15996789932251 - Sense= 0.8922166228294373 - POS= 0.15474078059196472 - TOTAL= 3.269282579421997\n","Iteration: 300\n","Training Losses:  - Iter: 305 / 9962 - Masked LM= 2.540989875793457 - Sense= 0.027296464890241623 - POS= 0.1409524530172348 - TOTAL= 1.9239320755004883\n","Iteration: 305\n","Training Losses:  - Iter: 310 / 9962 - Masked LM= 1.9417250156402588 - Sense= 0.6552371382713318 - POS= 0.3737897574901581 - TOTAL= 1.5919584035873413\n","Iteration: 310\n","Training Losses:  - Iter: 315 / 9962 - Masked LM= 3.832859754562378 - Sense= 1.0205230712890625 - POS= 0.41442030668258667 - TOTAL= 3.0691652297973633\n","Iteration: 315\n","Training Losses:  - Iter: 320 / 9962 - Masked LM= 7.776172637939453 - Sense= 0.29251667857170105 - POS= 0.08375642448663712 - TOTAL= 5.884382724761963\n","Iteration: 320\n","Training Losses:  - Iter: 325 / 9962 - Masked LM= 4.892967700958252 - Sense= 0.5737175345420837 - POS= 0.32012027502059937 - TOTAL= 3.7877955436706543\n","Iteration: 325\n","Training Losses:  - Iter: 330 / 9962 - Masked LM= 0.0 - Sense= 0.9172674417495728 - POS= 0.005458533763885498 - TOTAL= 0.13813598453998566\n","Iteration: 330\n","Training Losses:  - Iter: 335 / 9962 - Masked LM= 6.245143890380859 - Sense= 0.3087174594402313 - POS= 0.5694786906242371 - TOTAL= 4.787113189697266\n","Iteration: 335\n","Training Losses:  - Iter: 340 / 9962 - Masked LM= 6.636810302734375 - Sense= 0.40943291783332825 - POS= 0.3995194733142853 - TOTAL= 5.07897424697876\n","Iteration: 340\n","Training Losses:  - Iter: 345 / 9962 - Masked LM= 1.0735712051391602 - Sense= 0.249232679605484 - POS= 0.15165022015571594 - TOTAL= 0.8577283620834351\n","Iteration: 345\n","Training Losses:  - Iter: 350 / 9962 - Masked LM= 3.6674177646636963 - Sense= 0.4565556049346924 - POS= 0.3270961344242096 - TOTAL= 2.8517563343048096\n","Iteration: 350\n","Training Losses:  - Iter: 355 / 9962 - Masked LM= 2.998528480529785 - Sense= 0.26034319400787354 - POS= 0.06235568970441818 - TOTAL= 2.2941834926605225\n","Iteration: 355\n","Training Losses:  - Iter: 360 / 9962 - Masked LM= 6.000829696655273 - Sense= 0.17975011467933655 - POS= 0.20813654363155365 - TOTAL= 4.548398494720459\n","Iteration: 360\n","Training Losses:  - Iter: 365 / 9962 - Masked LM= 3.6652963161468506 - Sense= 0.3058086633682251 - POS= 0.2822115123271942 - TOTAL= 2.8230645656585693\n","Iteration: 365\n","Training Losses:  - Iter: 370 / 9962 - Masked LM= 3.3525307178497314 - Sense= 0.24624471366405487 - POS= 0.2938635051250458 - TOTAL= 2.580721139907837\n","Iteration: 370\n","Training Losses:  - Iter: 375 / 9962 - Masked LM= 2.294145107269287 - Sense= 0.3959646224975586 - POS= 0.27345573902130127 - TOTAL= 1.8073490858078003\n","Iteration: 375\n","Training Losses:  - Iter: 380 / 9962 - Masked LM= 2.769129514694214 - Sense= 0.5149176716804504 - POS= 0.18141476809978485 - TOTAL= 2.1722261905670166\n","Iteration: 380\n","Training Losses:  - Iter: 385 / 9962 - Masked LM= 4.126607418060303 - Sense= 0.5341511964797974 - POS= 0.3410751223564148 - TOTAL= 3.2091856002807617\n","Iteration: 385\n","Training Losses:  - Iter: 390 / 9962 - Masked LM= 1.0594990253448486 - Sense= 0.3595481812953949 - POS= 0.19450053572654724 - TOTAL= 0.8680065870285034\n","Iteration: 390\n","Training Losses:  - Iter: 395 / 9962 - Masked LM= 3.532278299331665 - Sense= 0.9950479865074158 - POS= 0.30675628781318665 - TOTAL= 2.829141616821289\n","Iteration: 395\n","Training Losses:  - Iter: 400 / 9962 - Masked LM= 0.29718017578125 - Sense= 0.1012658104300499 - POS= 0.01894085854291916 - TOTAL= 0.23996908962726593\n","Iteration: 400\n","Training Losses:  - Iter: 405 / 9962 - Masked LM= 0.28101253509521484 - Sense= 0.28318747878074646 - POS= 0.15014994144439697 - TOTAL= 0.26825252175331116\n","Iteration: 405\n","Training Losses:  - Iter: 410 / 9962 - Masked LM= 6.341938018798828 - Sense= 0.20476053655147552 - POS= 0.04325361177325249 - TOTAL= 4.791492938995361\n","Iteration: 410\n","Training Losses:  - Iter: 415 / 9962 - Masked LM= 2.722393035888672 - Sense= 0.999265193939209 - POS= 0.6698192358016968 - TOTAL= 2.258666515350342\n","Iteration: 415\n","Training Losses:  - Iter: 420 / 9962 - Masked LM= 1.257307767868042 - Sense= 0.24336621165275574 - POS= 0.45101398229599 - TOTAL= 1.0245871543884277\n","Iteration: 420\n","Training Losses:  - Iter: 425 / 9962 - Masked LM= 4.620914459228516 - Sense= 0.3421996831893921 - POS= 0.2308672070503235 - TOTAL= 3.540102481842041\n","Iteration: 425\n","Training Losses:  - Iter: 430 / 9962 - Masked LM= 5.01650333404541 - Sense= 0.4997962415218353 - POS= 0.2629210650920868 - TOTAL= 3.8636391162872314\n","Iteration: 430\n","Training Losses:  - Iter: 435 / 9962 - Masked LM= 1.4230618476867676 - Sense= 0.3222648501396179 - POS= 0.31434565782546997 - TOTAL= 1.1470706462860107\n","Iteration: 435\n","Training Losses:  - Iter: 440 / 9962 - Masked LM= 2.887319326400757 - Sense= 0.5692455768585205 - POS= 0.3151814341545105 - TOTAL= 2.2823944091796875\n","Iteration: 440\n","Training Losses:  - Iter: 445 / 9962 - Masked LM= 4.737583637237549 - Sense= 0.1763117015361786 - POS= 0.8748975992202759 - TOTAL= 3.6671245098114014\n","Iteration: 445\n","Training Losses:  - Iter: 450 / 9962 - Masked LM= 4.327939033508301 - Sense= 0.40295544266700745 - POS= 0.5571913719177246 - TOTAL= 3.362116813659668\n","Iteration: 450\n","Training Losses:  - Iter: 455 / 9962 - Masked LM= 6.442788600921631 - Sense= 0.3861369788646698 - POS= 0.12360350042581558 - TOTAL= 4.902372360229492\n","Iteration: 455\n","Training Losses:  - Iter: 460 / 9962 - Masked LM= 1.3763999938964844 - Sense= 0.5828394889831543 - POS= 0.4682339131832123 - TOTAL= 1.1665493249893188\n","Iteration: 460\n","Training Losses:  - Iter: 465 / 9962 - Masked LM= 4.792211532592773 - Sense= 0.646521270275116 - POS= 0.3013944923877716 - TOTAL= 3.72127628326416\n","Iteration: 465\n","Training Losses:  - Iter: 470 / 9962 - Masked LM= 2.070967435836792 - Sense= 0.39234086871147156 - POS= 0.16638411581516266 - TOTAL= 1.6287150382995605\n","Iteration: 470\n","Training Losses:  - Iter: 475 / 9962 - Masked LM= 0.0 - Sense= 0.3169839084148407 - POS= 0.09056790173053741 - TOTAL= 0.056604381650686264\n","Iteration: 475\n","Training Losses:  - Iter: 480 / 9962 - Masked LM= 0.0 - Sense= 0.04116448014974594 - POS= 0.03883449360728264 - TOTAL= 0.010058121755719185\n","Iteration: 480\n","Training Losses:  - Iter: 485 / 9962 - Masked LM= 0.9933795928955078 - Sense= 0.14900358021259308 - POS= 0.18806254863739014 - TOTAL= 0.7861915230751038\n","Iteration: 485\n","Training Losses:  - Iter: 490 / 9962 - Masked LM= 3.311509132385254 - Sense= 0.3193814158439636 - POS= 0.19049663841724396 - TOTAL= 2.550588607788086\n","Iteration: 490\n","Training Losses:  - Iter: 495 / 9962 - Masked LM= 3.8094611167907715 - Sense= 0.5515861511230469 - POS= 0.13364450633525848 - TOTAL= 2.953198194503784\n","Iteration: 495\n","Training Losses:  - Iter: 500 / 9962 - Masked LM= 4.8071465492248535 - Sense= 0.29149025678634644 - POS= 0.7214967608451843 - TOTAL= 3.721233367919922\n","Iteration: 500\n","Training Losses:  - Iter: 505 / 9962 - Masked LM= 3.2619106769561768 - Sense= 0.2257467657327652 - POS= 0.12314891070127487 - TOTAL= 2.492609977722168\n","Iteration: 505\n","Training Losses:  - Iter: 510 / 9962 - Masked LM= 0.0 - Sense= 0.08089882135391235 - POS= 0.231465682387352 - TOTAL= 0.03528138995170593\n","Iteration: 510\n","Training Losses:  - Iter: 515 / 9962 - Masked LM= 2.612699031829834 - Sense= 0.27051112055778503 - POS= 0.7652990221977234 - TOTAL= 2.0766308307647705\n","Iteration: 515\n","Training Losses:  - Iter: 520 / 9962 - Masked LM= 6.543689250946045 - Sense= 0.5435245633125305 - POS= 0.29115262627601624 - TOTAL= 5.018410682678223\n","Iteration: 520\n","Training Losses:  - Iter: 525 / 9962 - Masked LM= 4.734079837799072 - Sense= 0.8865125775337219 - POS= 0.6213954091072083 - TOTAL= 3.7456765174865723\n","Iteration: 525\n","Training Losses:  - Iter: 530 / 9962 - Masked LM= 0.3961540758609772 - Sense= 0.36752331256866455 - POS= 0.08325589448213577 - TOTAL= 0.36056965589523315\n","Iteration: 530\n","Training Losses:  - Iter: 535 / 9962 - Masked LM= 1.2360471487045288 - Sense= 0.34295547008514404 - POS= 0.20548847317695618 - TOTAL= 0.9990274906158447\n","Iteration: 535\n","Training Losses:  - Iter: 540 / 9962 - Masked LM= 3.5096328258514404 - Sense= 0.388349711894989 - POS= 0.14763034880161285 - TOTAL= 2.705240249633789\n","Iteration: 540\n","Training Losses:  - Iter: 545 / 9962 - Masked LM= 3.0205962657928467 - Sense= 0.35333728790283203 - POS= 0.49187418818473816 - TOTAL= 2.3676352500915527\n","Iteration: 545\n","Training Losses:  - Iter: 550 / 9962 - Masked LM= 1.55499267578125 - Sense= 0.21973106265068054 - POS= 0.17998482286930084 - TOTAL= 1.2172026634216309\n","Iteration: 550\n","Training Losses:  - Iter: 555 / 9962 - Masked LM= 0.0 - Sense= 0.008744478225708008 - POS= 0.0035363039933145046 - TOTAL= 0.0016653022030368447\n","Iteration: 555\n","Training Losses:  - Iter: 560 / 9962 - Masked LM= 2.8828060626983643 - Sense= 0.7795842885971069 - POS= 0.6606060862541199 - TOTAL= 2.3451027870178223\n","Iteration: 560\n","Training Losses:  - Iter: 565 / 9962 - Masked LM= 1.4681715965270996 - Sense= 0.4747655391693115 - POS= 0.5073774456977844 - TOTAL= 1.2230812311172485\n","Iteration: 565\n","Training Losses:  - Iter: 570 / 9962 - Masked LM= 0.0 - Sense= 0.0009937286376953125 - POS= 0.09643381834030151 - TOTAL= 0.009792441502213478\n","Iteration: 570\n","Training Losses:  - Iter: 575 / 9962 - Masked LM= 2.495042324066162 - Sense= 0.22880055010318756 - POS= 0.19686545431613922 - TOTAL= 1.925288438796997\n","Iteration: 575\n","Training Losses:  - Iter: 580 / 9962 - Masked LM= 5.973953723907471 - Sense= 0.18336832523345947 - POS= 0.44431400299072266 - TOTAL= 4.552402019500732\n","Iteration: 580\n","Training Losses:  - Iter: 585 / 9962 - Masked LM= 2.237490653991699 - Sense= 0.4755634665489197 - POS= 0.1254609376192093 - TOTAL= 1.7619985342025757\n","Iteration: 585\n","Training Losses:  - Iter: 590 / 9962 - Masked LM= 1.9968156814575195 - Sense= 0.2205507755279541 - POS= 0.029535958543419838 - TOTAL= 1.5336480140686035\n","Iteration: 590\n","Training Losses:  - Iter: 595 / 9962 - Masked LM= 4.566334247589111 - Sense= 0.26910659670829773 - POS= 0.1835557222366333 - TOTAL= 3.4834723472595215\n","Iteration: 595\n","Training Losses:  - Iter: 600 / 9962 - Masked LM= 3.7474074363708496 - Sense= 0.4422018229961395 - POS= 0.8927893042564392 - TOTAL= 2.9661645889282227\n","Iteration: 600\n","Training Losses:  - Iter: 605 / 9962 - Masked LM= 1.012977957725525 - Sense= 0.2847534120082855 - POS= 0.0326344259083271 - TOTAL= 0.8057098388671875\n","Iteration: 605\n","Training Losses:  - Iter: 610 / 9962 - Masked LM= 2.26057767868042 - Sense= 0.38044044375419617 - POS= 0.21711908280849457 - TOTAL= 1.7742112874984741\n","Iteration: 610\n","Training Losses:  - Iter: 615 / 9962 - Masked LM= 2.737666130065918 - Sense= 0.7341453433036804 - POS= 0.5587531328201294 - TOTAL= 2.2192466259002686\n","Iteration: 615\n","Training Losses:  - Iter: 620 / 9962 - Masked LM= 2.1065690517425537 - Sense= 0.7864907383918762 - POS= 0.09682569652795792 - TOTAL= 1.7075828313827515\n","Iteration: 620\n","Training Losses:  - Iter: 625 / 9962 - Masked LM= 5.2709126472473145 - Sense= 0.09741164743900299 - POS= 0.257319837808609 - TOTAL= 3.993528366088867\n","Iteration: 625\n","Training Losses:  - Iter: 630 / 9962 - Masked LM= 1.0137691497802734 - Sense= 0.3940769135951996 - POS= 0.12034539133310318 - TOTAL= 0.8314729332923889\n","Iteration: 630\n","Training Losses:  - Iter: 635 / 9962 - Masked LM= 4.381082534790039 - Sense= 0.822551429271698 - POS= 0.28553906083106995 - TOTAL= 3.437748670578003\n","Iteration: 635\n","Training Losses:  - Iter: 640 / 9962 - Masked LM= 4.546174049377441 - Sense= 0.7943251132965088 - POS= 0.25634899735450745 - TOTAL= 3.5544142723083496\n","Iteration: 640\n","Training Losses:  - Iter: 645 / 9962 - Masked LM= 0.0 - Sense= 0.10052186995744705 - POS= 0.2815011143684387 - TOTAL= 0.0432283915579319\n","Iteration: 645\n","Training Losses:  - Iter: 650 / 9962 - Masked LM= 1.728592872619629 - Sense= 0.18553426861763 - POS= 0.282244473695755 - TOTAL= 1.35249924659729\n","Iteration: 650\n","Training Losses:  - Iter: 655 / 9962 - Masked LM= 1.4368915557861328 - Sense= 0.6964168548583984 - POS= 0.06491701304912567 - TOTAL= 1.1886228322982788\n","Iteration: 655\n","Training Losses:  - Iter: 660 / 9962 - Masked LM= 0.0 - Sense= 0.16382309794425964 - POS= 0.27017709612846375 - TOTAL= 0.0515911765396595\n","Iteration: 660\n","Training Losses:  - Iter: 665 / 9962 - Masked LM= 0.0 - Sense= 0.33419403433799744 - POS= 0.01387720089405775 - TOTAL= 0.0515168271958828\n","Iteration: 665\n","Training Losses:  - Iter: 670 / 9962 - Masked LM= 3.3104183673858643 - Sense= 0.38023215532302856 - POS= 0.20482808351516724 - TOTAL= 2.560331344604492\n","Iteration: 670\n","Training Losses:  - Iter: 675 / 9962 - Masked LM= 1.989039421081543 - Sense= 0.16569824516773224 - POS= 0.45620250701904297 - TOTAL= 1.562254548072815\n","Iteration: 675\n","Training Losses:  - Iter: 680 / 9962 - Masked LM= 3.5248634815216064 - Sense= 0.49897849559783936 - POS= 0.7084917426109314 - TOTAL= 2.7893435955047607\n","Iteration: 680\n","Training Losses:  - Iter: 685 / 9962 - Masked LM= 3.652832508087158 - Sense= 0.2563428282737732 - POS= 0.4062957167625427 - TOTAL= 2.8187055587768555\n","Iteration: 685\n","Training Losses:  - Iter: 690 / 9962 - Masked LM= 2.611215829849243 - Sense= 0.33065351843833923 - POS= 0.4594610631465912 - TOTAL= 2.0539560317993164\n","Iteration: 690\n","Training Losses:  - Iter: 695 / 9962 - Masked LM= 0.06968307495117188 - Sense= 0.2703346014022827 - POS= 0.7218600511550903 - TOTAL= 0.16499850153923035\n","Iteration: 695\n","Training Losses:  - Iter: 700 / 9962 - Masked LM= 0.3760948181152344 - Sense= 0.5614609122276306 - POS= 0.05386808142066002 - TOTAL= 0.37167707085609436\n","Iteration: 700\n","Training Losses:  - Iter: 705 / 9962 - Masked LM= 7.276597499847412 - Sense= 0.5184739828109741 - POS= 0.46766647696495056 - TOTAL= 5.581985950469971\n","Iteration: 705\n","Training Losses:  - Iter: 710 / 9962 - Masked LM= 0.0 - Sense= 0.02923736535012722 - POS= 0.06669151782989502 - TOTAL= 0.011054757051169872\n","Iteration: 710\n","Training Losses:  - Iter: 715 / 9962 - Masked LM= 5.631865501403809 - Sense= 0.4246962070465088 - POS= 0.4388000965118408 - TOTAL= 4.331483364105225\n","Iteration: 715\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"K7onxqYe37k_","colab_type":"code","colab":{}},"source":["#Save your POS model in case the internal autosave missed his shot at the end of the run\n","torch.save(pos_model.state_dict(), '/content/drive/My Drive/CSI5138_Project/Models/Common/PosModel.pt') "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RVlcs6HOKFR2","colab_type":"code","colab":{}},"source":["#Save your Sense model in case the internal autosave missed his shot at the end of the run\n","torch.save(sense_model.state_dict(), '/content/drive/My Drive/CSI5138_Project/Models/Common/SenseModel.pt') "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bcDne0NZCCpL","colab_type":"code","outputId":"857907fe-fabf-4608-8250-839f52b53b5d","executionInfo":{"status":"ok","timestamp":1574998814515,"user_tz":300,"elapsed":1087,"user":{"displayName":"Simon Fortier-Garceau","photoUrl":"","userId":"08177308718689968362"}},"colab":{"base_uri":"https://localhost:8080/","height":326}},"source":["#Look into POS predictions explicitly\n","sample_set = next(iter(trainloader))\n","sample_set = tuple(t.cuda() for t in sample_set)\n","# Unpack the inputs from our dataloader\n","input_ids, attention_mask, sense_ids, pos_ids, lemma_ids, embedding_intervals, sense_spaceids = sample_set\n","pos_model.eval()\n","\n","pos_predictions = pos_model(input_ids, attention_mask, embedding_intervals, roberta_model)\n","pos_ids = torch.tensor([pos.view(-1) for pos in pos_ids.view(-1) if pos.item() != -1], dtype=torch.long)\n","pos_ids = pos_ids.cuda()\n","# Computer the loss for the POS predictions\n","for pred, label in zip(pos_predictions, pos_ids):\n","  pred_id = torch.argmax(torch.tensor(torch.nn.functional.softmax(pred))).item()\n","  label_id = label.item()\n","  print('Prediction:', SEMCOR_VOCAB.convertPOSID_to_POS(pred_id),'  Actual:', SEMCOR_VOCAB.convertPOSID_to_POS(label_id))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Prediction: PRP   Actual: PRP\n","Prediction: VBD   Actual: VBD\n","Prediction: VB   Actual: VB\n","Prediction: IN   Actual: IN\n","Prediction: PRP   Actual: PRP\n","Prediction: VB   Actual: VB\n","Prediction: NN   Actual: NN\n","Prediction: IN   Actual: VB\n","Prediction: WDT   Actual: WDT\n","Prediction: TO   Actual: TO\n","Prediction: VB   Actual: VB\n","Prediction: PRP   Actual: PRP\n","Prediction: PUNC   Actual: PUNC\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  if sys.path[0] == '':\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  if sys.path[0] == '':\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"YENpvizqpnVa","colab_type":"code","outputId":"6db65909-d927-4088-85e9-0113b02e7a93","executionInfo":{"status":"ok","timestamp":1574998819412,"user_tz":300,"elapsed":850,"user":{"displayName":"Simon Fortier-Garceau","photoUrl":"","userId":"08177308718689968362"}},"colab":{"base_uri":"https://localhost:8080/","height":564}},"source":["#Look into Sense predictions explicitly\n","sample_set = next(iter(trainloader))\n","sample_set = tuple(t.cuda() for t in sample_set)\n","# Unpack the inputs from our dataloader\n","input_ids, attention_mask, sense_ids, pos_ids, lemma_ids, embedding_intervals, sense_spaceids = sample_set\n","sense_model.eval()\n","\n","sense_predictions = sense_model(input_ids, attention_mask, embedding_intervals, roberta_model)\n","sense_spaceids = torch.tensor([sense.view(-1) for sense in sense_spaceids.view(-1) if sense.item() != -1], dtype=torch.long)\n","sense_spaceids = sense_spaceids.cuda()\n","\n","print(len(sense_predictions))\n","print(len(sense_spaceids))\n","\n","# Computer the loss for the POS predictions\n","for pred, label in zip(sense_predictions, sense_spaceids):\n","  pred_id = torch.argmax(torch.tensor(torch.nn.functional.softmax(pred))).item()\n","  label_id = label.item()\n","  print('Prediction:', pred_id,'  Actual:', label_id)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["25\n","25\n","Prediction: 0   Actual: 0\n","Prediction: 1   Actual: 1\n","Prediction: 0   Actual: 0\n","Prediction: 0   Actual: 0\n","Prediction: 0   Actual: 0\n","Prediction: 0   Actual: 0\n","Prediction: 11   Actual: 11\n","Prediction: 3   Actual: 3\n","Prediction: 0   Actual: 0\n","Prediction: 0   Actual: 0\n","Prediction: 0   Actual: 0\n","Prediction: 0   Actual: 1\n","Prediction: 0   Actual: 0\n","Prediction: 1   Actual: 1\n","Prediction: 0   Actual: 0\n","Prediction: 0   Actual: 1\n","Prediction: 8   Actual: 1\n","Prediction: 0   Actual: 0\n","Prediction: 1   Actual: 1\n","Prediction: 0   Actual: 0\n","Prediction: 0   Actual: 0\n","Prediction: 1   Actual: 1\n","Prediction: 8   Actual: 8\n","Prediction: 0   Actual: 0\n","Prediction: 0   Actual: 0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  app.launch_new_instance()\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  app.launch_new_instance()\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"7WivKJcxG8R9","colab_type":"code","outputId":"64474714-cc52-4988-fa12-9c6cd21ba68a","executionInfo":{"status":"ok","timestamp":1574988030312,"user_tz":300,"elapsed":342,"user":{"displayName":"Simon Fortier-Garceau","photoUrl":"","userId":"08177308718689968362"}},"colab":{"base_uri":"https://localhost:8080/","height":561}},"source":["\n","import pandas as pd\n","\n","# initialize statistics\n","stats = {'Validation loss':val_losses,\n","         'Mask loss':mask_losses,\n","         'Sense loss':sense_losses,\n","         'POS loss':pos_losses\n","        } \n","\n","df = pd.DataFrame(stats)\n","\n","# Print the output.\n","print(df)\n","\n","df.to_csv('/content/drive/My Drive/CSI5138_Project/Models/Common/Sense Model Statistics.csv') "],"execution_count":0,"outputs":[{"output_type":"stream","text":["    Validation loss  Mask loss  Sense loss  POS loss\n","0          3.345792  12.248918    3.345792         0\n","1          0.810763  11.964904    0.810763         0\n","2          0.743795  11.786527    0.743795         0\n","3          0.707798  11.862141    0.707798         0\n","4          0.678341  11.748346    0.678341         0\n","5          0.647736  11.817362    0.647736         0\n","6          0.641424  11.655198    0.641424         0\n","7          0.627400  11.839826    0.627400         0\n","8          0.610439  12.123139    0.610439         0\n","9          0.600016  12.389878    0.600016         0\n","10         0.591979  11.635879    0.591979         0\n","11         0.584649  12.240495    0.584649         0\n","12         0.569209  12.222164    0.569209         0\n","13         0.578041  11.613862    0.578041         0\n","14         0.567608  11.877170    0.567608         0\n","15         0.562663  11.796820    0.562663         0\n","16         0.551436  11.899391    0.551436         0\n","17         0.551249  11.826182    0.551249         0\n","18         0.543102  12.008387    0.543102         0\n","19         0.539302  11.844368    0.539302         0\n","20         0.540225  11.877184    0.540225         0\n","21         0.543455  11.907974    0.543455         0\n","22         0.544905  11.913091    0.544905         0\n","23         0.530814  11.746147    0.530814         0\n","24         0.531692  11.981900    0.531692         0\n","25         0.529100  11.983804    0.529100         0\n","26         0.522525  11.866344    0.522525         0\n","27         0.523783  11.726187    0.523783         0\n","28         0.525125  12.166930    0.525125         0\n","29         0.527945  12.042511    0.527945         0\n","30         0.516728  11.893811    0.516728         0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U0eSX24obvu9","colab_type":"text"},"source":["## WiC Training and Validation"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ym1MeMZzcMkG"},"source":["### Load the WiC data"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"d4cec4ff-7cbf-40a0-9816-ebe7e809247b","executionInfo":{"status":"ok","timestamp":1574403675502,"user_tz":300,"elapsed":1055,"user":{"displayName":"Julian Templeton","photoUrl":"","userId":"10145264682205780329"}},"id":"HlLmvZNmYhyJ","colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["#LOAD THE WIC TRAINING DATA ON A DATALOADER\n","train_json_objs = load_json_objects_from_file(\"/content/drive/My Drive/CSI5138_Project/WiC/train.jsonl\")\n","#print(f\"Number of training exampled = {len(train_json_objs)}\")\n","#print(train_json_objs[5])\n","\n","\n","\n","# Process the data\n","raw_train_set = wic_preprocessing(train_json_objs, shuffle_data=False, verbose = False) # We do not want to shuffle for now.\n","\n","# Create a PyTorch dataset for it\n","train_data = TensorDataset(\n","    torch.tensor(raw_train_set[\"input_ids\"]),\n","    torch.tensor(raw_train_set[\"token_type_ids\"]),\n","    torch.tensor(raw_train_set[\"attention_mask\"]),\n","    torch.tensor(raw_train_set[\"labels\"]),\n","    torch.tensor(raw_train_set[\"word1_locs\"]),\n","    torch.tensor(raw_train_set[\"word2_locs\"])\n",")\n","\n","# Create a sampler and loader\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Number of training exampled = 5428\n","{'word': 'head', 'sentence1': 'His horse won by a head.', 'sentence2': 'He is two heads taller than his little sister.', 'idx': 5, 'label': True, 'start1': 19, 'start2': 10, 'end1': 23, 'end2': 15, 'version': 1.1}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"L005t3scZoza","colab":{}},"source":["#LOAD THE WIC TESTING AND VALIDATION DATA ON DATALOADERS\n","# Load the json objects from each file\n","test_json_objs = load_json_objects_from_file(\"/content/drive/My Drive/CSI5138_Project/WiC/test.jsonl\")\n","valid_json_objs = load_json_objects_from_file(\"/content/drive/My Drive/CSI5138_Project/WiC/val.jsonl\")\n","# Process the objects\n","raw_test_set = wic_preprocessing(test_json_objs, testing = False) # The labels for the testing set are unknown\n","raw_valid_set = wic_preprocessing(valid_json_objs)\n","# Create PyTorch datasets\n","test_data = TensorDataset(\n","    torch.tensor(raw_test_set[\"input_ids\"]),\n","    torch.tensor(raw_test_set[\"token_type_ids\"]),\n","    torch.tensor(raw_test_set[\"attention_mask\"]),\n","    torch.tensor(raw_test_set[\"word1_locs\"]),\n","    torch.tensor(raw_test_set[\"word2_locs\"])\n",")\n","validation_data = TensorDataset(\n","    torch.tensor(raw_valid_set[\"input_ids\"]),\n","    torch.tensor(raw_valid_set[\"token_type_ids\"]),\n","    torch.tensor(raw_valid_set[\"attention_mask\"]),\n","    torch.tensor(raw_valid_set[\"labels\"]),\n","    torch.tensor(raw_valid_set[\"word1_locs\"]),\n","    torch.tensor(raw_valid_set[\"word2_locs\"])\n",")\n","\n","# Create a sampler and loader for each\n","test_sampler = RandomSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tpz_9Vj7HxZx","colab_type":"text"},"source":["### Custom head class for WiC instead of a classification head\n","Based on https://pytorch.org/tutorials/beginner/examples_nn/two_layer_net_module.html and https://huggingface.co/transformers/_modules/transformers/modeling_roberta.html#RobertaModel\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"o1ibjlX5daB5","colab":{}},"source":["class WiCSemcorHead(torch.nn.Module):\n","    def __init__(self, roberta_based_model, embedding_size = 768):\n","        \"\"\"\n","        Keeps a reference to the provided RoBERTa model. \n","        It then adds a linear layer that takes the distance between two \n","        \"\"\"\n","        super(WiCSemcorHead, self).__init__()\n","        self.embedding_size = embedding_size\n","        self.embedder = roberta_based_model\n","        self.linear_diff = torch.nn.Linear(embedding_size, 250, bias = True)\n","        self.linear_seperator = torch.nn.Linear(250, 2, bias = True)\n","        self.loss = torch.nn.CrossEntropyLoss()\n","        self.activation = torch.nn.ReLU()\n","        self.softmax = torch.nn.Softmax()\n","\n","    def forward(self, input_ids=None, attention_mask=None, labels=None,\n","                word1_locs = None, word2_locs = None):\n","        \"\"\"\n","        Takes in the same argument as RoBERTa forward plus two tensors for the location of the 2 words to compare\n","        \"\"\"\n","        if word1_locs is None or word2_locs is None:\n","          raise ValueError(\"The tensors (word1_locs, word1_locs) containing the location of the words to compare in the input vector must be provided.\")\n","        elif input_ids is None:\n","          raise ValueError(\"The input_ids tensor must be provided.\")\n","        elif word1_locs.shape[0] != input_ids.shape[0] or word2_locs.shape[0] != input_ids.shape[0]:\n","          raise ValueError(\"All provided vectors should have the same batch size.\")\n","        batch_size = word1_locs.shape[0]\n","        # Get the embeddings\n","        embs, _ = self.embedder(input_ids=input_ids, attention_mask=attention_mask)\n","        # Get the words\n","        word1s = torch.matmul(word1_locs, embs).view(batch_size, self.embedding_size)\n","        word2s = torch.matmul(word2_locs, embs).view(batch_size, self.embedding_size)\n","        diff = word1s - word2s\n","        # Calculate outputs using activation\n","        layer1_results = self.activation(self.linear_diff(diff))\n","        logits = self.softmax(self.linear_seperator(layer1_results))\n","        outputs = logits\n","        # Calculate the loss\n","        if labels is not None:\n","            #  We want seperation like a SVM so use Hinge loss\n","            loss = self.loss(logits.view(-1, 2), labels.view(-1))\n","            outputs = (loss, logits)\n","        return outputs"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lSGBReDfe9WC","colab_type":"text"},"source":["### Instantiate the WiCSemcorHead"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kQIgh8ZbegmX","colab":{}},"source":["class_model = WiC_Head(roberta_model, embedding_size = 768)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"myJ08VFvzBXg","colab_type":"text"},"source":["### The training loop (fine-tuning Roberta right?)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"N08ULN5VevUG","colab":{}},"source":["# Want to maximize accuracy\n","max_val_acc = (0, 0)\n","# Put the model in GPU\n","class_model.cuda()\n","# Create the optimizer\n","param_optimizer = list(class_model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]\n","# I use the one that comes with the models, but any other optimizer could be used\n","optimizer = AdamW(optimizer_grouped_parameters, lr=1e-6)\n","# Store our loss and accuracy for plotting\n","fit_history = {\"loss\": [],  \"accuracy\": [], \"val_loss\": [], \"val_accuracy\": []}\n","epoch_number = 0\n","epoch_since_max = 0\n","continue_learning = True\n","while epoch_number < EPOCHS and continue_learning:\n","  epoch_number += 1\n","  print(f\"Training epoch #{epoch_number}\")\n","  # Tracking variables\n","  tr_loss, tr_accuracy = 0, 0\n","  nb_tr_examples, nb_tr_steps = 0, 0\n","  eval_loss, eval_accuracy = 0, 0\n","  nb_eval_steps, nb_eval_examples = 0, 0\n","  # Training\n","  # Set our model to training mode (as opposed to evaluation mode)\n","  class_model.train()\n","  # Freeze RoBERTa weights\n","  class_model.embedder.eval()\n","  # Train the data for one epoch\n","  for step, batch in enumerate(train_dataloader):\n","    # Add batch to GPU\n","    batch = tuple(t.cuda() for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_token_ids, b_input_mask, b_labels, b_word1, b_word2 = batch\n","    # Clear out the gradients (by default they accumulate)\n","    optimizer.zero_grad()\n","    # Forward pass\n","    #loss, logits = class_model(b_input_ids, token_type_ids=b_token_ids, attention_mask=b_input_mask, labels=b_labels)   \n","    loss, logits = class_model(b_input_ids, attention_mask=b_input_mask, \n","                               labels=b_labels, word1_locs = b_word1, word2_locs = b_word2) \n","    # Backward pass\n","    loss.backward()\n","    # Update parameters and take a step using the computed gradient\n","    optimizer.step()\n","    # Move logits and labels to CPU\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.cpu().numpy()\n","    # Calculate the accuracy\n","    b_accuracy = flat_accuracy(logits, label_ids) # For RobertaForClassification\n","    '''preds = []\n","    for logit in logits:\n","      if logit >= 0:\n","        preds.append([1])\n","      else:\n","        preds.append([-1])\n","    b_accuracy = accuracy_score(label_ids, preds)'''\n","    # Append to fit history\n","    fit_history[\"loss\"].append(loss.item()) \n","    fit_history[\"accuracy\"].append(b_accuracy) \n","    # Update tracking variables\n","    tr_loss += loss.item()\n","    tr_accuracy += b_accuracy\n","    nb_tr_examples += b_input_ids.size(0)\n","    nb_tr_steps += 1\n","    if nb_tr_steps%10 == 0:\n","      print(\"\\t\\tTraining Batch {}: Loss: {}; Accuracy: {}\".format(nb_tr_steps, loss.item(), b_accuracy))\n","  print(\"Training:\\n\\tLoss: {}; Accuracy: {}\".format(tr_loss/nb_tr_steps, tr_accuracy/nb_tr_steps))\n","  # Validation\n","  # Put model in evaluation mode to evaluate loss on the validation set\n","  class_model.eval()\n","  # Evaluate data for one epoch\n","  for batch in validation_dataloader:\n","    # Add batch to GPU\n","    batch = tuple(t.cuda() for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_token_ids, b_input_mask, b_labels, b_word1, b_word2 = batch\n","    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","    with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      #loss, logits = class_model(b_input_ids, token_type_ids=b_token_ids, attention_mask=b_input_mask, labels=b_labels)\n","      loss, logits = class_model(b_input_ids, attention_mask=b_input_mask, \n","                                 labels=b_labels, word1_locs = b_word1, word2_locs = b_word2)\n","    # Move logits and labels to CPU\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.cpu().numpy()\n","    # Calculate the accuracy\n","    b_accuracy = flat_accuracy(logits, label_ids) # For RobertaForClassification\n","    '''preds = []\n","    for logit in logits:\n","      if logit >= 0:\n","        preds.append([1])\n","      else:\n","        preds.append([-1])\n","    b_accuracy = accuracy_score(label_ids, preds)'''\n","    # Append to fit history\n","    fit_history[\"val_loss\"].append(loss.item()) \n","    fit_history[\"val_accuracy\"].append(b_accuracy) \n","    # Update tracking variables\n","    eval_loss += loss.item()\n","    eval_accuracy += b_accuracy\n","    nb_eval_examples += b_input_ids.size(0)\n","    nb_eval_steps += 1\n","    if nb_eval_steps%10 == 0:\n","      print(\"\\t\\tValidation Batch {}: Loss: {}; Accuracy: {}\".format(nb_eval_steps, loss.item(), b_accuracy))\n","  eval_acc = eval_accuracy/nb_eval_steps\n","  if eval_acc >= max_val_acc[0]:\n","    max_val_acc = (eval_acc, epoch_number)\n","    continue_learning = True\n","    epoch_since_max = 0 # New max\n","  else:\n","    epoch_since_max += 1\n","    if epoch_since_max> PATIENCE:\n","      continue_learning = False # Stop learning, starting to overfit\n","  print(\"Validation:\\n\\tLoss={}; Accuracy: {}\".format(eval_loss/nb_eval_steps, eval_accuracy/nb_eval_steps))\n","print(f\"Best accuracy ({max_val_acc[0]}) obtained at epoch #{max_val_acc[1]}.\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gZwHpGrpYhj5","colab_type":"text"},"source":["### Get the testing results\n","DOES NOT WORK FOR NOW. WE DO NOT HAVE THE TESTING LABELS FOR WiC."]},{"cell_type":"code","metadata":{"id":"OLCnprHcYgxj","colab_type":"code","colab":{}},"source":["# Testing\n","# Put model in evaluation mode to evaluate loss on the validation set\n","class_model.eval()\n","# Evaluate data for one epoch\n","for batch in test_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.cuda() for t in batch)\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_token_ids, b_input_mask, b_labels = batch\n","  # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","  with torch.no_grad():\n","    # Forward pass, calculate logit predictions\n","    #loss, logits = class_model(b_input_ids, token_type_ids=b_token_ids, attention_mask=b_input_mask, labels=b_labels)\n","    loss, logits = class_model(b_input_ids, attention_mask=b_input_mask)\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.cpu().numpy()\n","  # Calculate the accuracy\n","  b_accuracy = flat_accuracy(logits, label_ids)\n","  # Append to fit history\n","  fit_history[\"val_loss\"].append(loss.item()) \n","  fit_history[\"val_accuracy\"].append(b_accuracy) \n","  # Update tracking variables\n","  eval_loss += loss.item()\n","  eval_accuracy += b_accuracy\n","  nb_eval_examples += b_input_ids.size(0)\n","  nb_eval_steps += 1\n","  if nb_eval_steps%10 == 0:\n","    print(\"\\t\\tTest Batch {}: Loss: {}; Accuracy: {}\".format(nb_eval_steps, loss.item(), b_accuracy))\n","# Print final results\n","print(\"Testing:\\n\\tLoss={}; Accuracy: {}\".format(eval_loss/nb_eval_steps, eval_accuracy/nb_eval_steps))"],"execution_count":0,"outputs":[]}]}